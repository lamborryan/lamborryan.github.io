<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[追风的蓝宝]]></title>
  <link href="www.lamborryan.com/atom.xml" rel="self"/>
  <link href="www.lamborryan.com/"/>
  <updated>2018-01-09T22:19:32+08:00</updated>
  <id>www.lamborryan.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.coderforart.com/">CoderForArt</generator>

  
  <entry>
    <title type="html"><![CDATA[Solr4.8.0源码分析汇总]]></title>
    <link href="www.lamborryan.com/15155074940397.html"/>
    <updated>2018-01-09T22:18:14+08:00</updated>
    <id>www.lamborryan.com/15155074940397.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">简介</a>
</li>
<li>
<a href="#toc_1">目录</a>
</li>
<li>
<a href="#toc_2">总结</a>
</li>
</ul>


<h2 id="toc_0">简介</h2>

<p>由于第一份工作是关于搜索引擎的, 所以当初也痴迷过Solr, 也花了两年时间研究了Solr.</p>

<p>因此以前在<a href="http://www.cnblogs.com/rcfeng/">博客园</a>写了不少关于Solr/SolrCloud的博客, 文章有点多就不一一迁移过来了, 就在这里建个导航。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">目录</h2>

<ul>
<li><a href="http://www.cnblogs.com/rcfeng/p/3911342.html">Solr4.8.0源码分析(1)之Solr的Servlet</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/3911482.html">Solr4.8.0源码分析(2)之Solr的启动(一)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/3915797.html">Solr4.8.0源码分析(3)之index的线程池管理</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/3923490.html">Solr4.8.0源码分析(4)之Eclipse Solr调试环境搭建</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/3923534.html">Solr4.8.0源码分析(5)之查询流程分析总述</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/3928356.html">Solr4.8.0源码分析(6)之非排序查询</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/3932045.html">Solr4.8.0源码分析(7)之Solr SPI</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/3972024.html">Solr4.8.0源码分析(8)之Lucene的索引文件(1)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/3976135.html">Solr4.8.0源码分析(9)之Lucene的索引文件(2)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/3983876.html">Solr4.8.0源码分析(10)之Lucene的索引文件(3)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/3987364.html">Solr4.8.0源码分析(11)之Lucene的索引文件(4)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4012337.html">Solr4.8.0源码分析(12)之Lucene的索引文件(5)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4044763.html">Solr4.8.0源码分析(13)之LuceneCore的索引修复</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4088506.html">Solr4.8.0源码分析(14) 之 SolrCloud索引深入(1)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4088563.html">Solr4.8.0源码分析(15) 之 SolrCloud索引深入(2)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4104669.html">Solr4.8.0源码分析(16)之SolrCloud索引深入(3)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4109700.html">Solr4.8.0源码分析(17)之SolrCloud索引深入(4)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4119957.html">Solr4.8.0源码分析(18)之缓存机制(一)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4127406.html">Solr4.8.0源码分析(19)之缓存机制(二)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4145349.html">Solr4.8.0源码分析(20)之SolrCloud的Recovery策略(一)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4147711.html">Solr4.8.0源码分析(21)之SolrCloud的Recovery策略(二)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4148733.html">Solr4.8.0源码分析(22)之SolrCloud的Recovery策略(三)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4152183.html">Solr4.8.0源码分析(23)之SolrCloud的Recovery策略(四)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4154462.html">Solr4.8.0源码分析(24)之SolrCloud的Recovery策略(五)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4158828.html">Solr4.8.0源码分析(25)之SolrCloud的Split流程(一)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4287030.html">Solr4.8.0源码分析(26)之Recovery失败造成的宕机原因分析</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4287031.html">Solr4.8.0源码分析(27)之ImplicitDocRouter和CompositeIdRouter</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4064065.html">Solr In Action 笔记(1) 之 Key Solr Concepts</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4067896.html">Solr In Action 笔记(2) 之评分机制(相似性计算)</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4077663.html">Solr In Action 笔记(3) 之 SolrCloud基础</a></li>
<li><a href="http://www.cnblogs.com/rcfeng/p/4082568.html">Solr In Action 笔记(4) 之 SolrCloud Index 基础</a></li>
</ul>

<h2 id="toc_2">总结</h2>

<p>很怀念当初在Unview和大家一起奋斗的日子, 也很庆幸当初刚毕业就进入了大数据团队。</p>

<p>本文完</p>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://www.lamborryan.com">Lamborryan</a>，作者：<a href="http://www.lamborryan.com/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://www.lamborryan.com/solr-4.8.0">http://www.lamborryan.com/solr-4.8.0</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gobblin系列(8)之Extractor源码分析]]></title>
    <link href="www.lamborryan.com/15155073098227.html"/>
    <updated>2018-01-09T22:15:09+08:00</updated>
    <id>www.lamborryan.com/15155073098227.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">一. 简介</a>
</li>
<li>
<a href="#toc_1">二. MysqlExtractor的类继承关系。</a>
</li>
<li>
<a href="#toc_2">三. Extractor接口</a>
</li>
<li>
<a href="#toc_3">四: QueryBasedExtractor</a>
</li>
<li>
<a href="#toc_4">五: JdbcExtractor 和 MysqlExtractor</a>
</li>
<li>
<a href="#toc_5">六: 总结</a>
<ul>
<li>
<a href="#toc_6">本文完</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">一. 简介</h2>

<p>Extractor相比Source来说就简单多了, 因为Source不但要考虑当前job的WorkUnits, 还要考虑前一个Job的WorkUnits. 相比之下Extractor的服务对象就单个WorkUnits, 要实现的功能也无非就是根据low water mark和high water mark从数据源那里获取数据。</p>

<p>因此本文主要介绍Extractor如何实现上述描述的功能。目前Gobblin支持且常用的Extractor有MysqlExtractor, KafkaSimpleSource等等, 本文依然以MysqlExtractor为例来介绍Extractor。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">二. MysqlExtractor的类继承关系。</h2>

<p><img src="media/15155073098227/gobblin-extractor-1.png" alt="gobblin-extractor-1"/></p>

<p>由此可见, 要实现MysqlExtractor不但需要继承Extractor, 也要继承实现该数据源有关的SpecificLayer接口。</p>

<h2 id="toc_2">三. Extractor接口</h2>

<p>现在让我们来看下Extractor接口实现了哪些功能:</p>

<ul>
<li>获取record的数据结构</li>
<li>读取record</li>
<li>获取record的个数</li>
<li>获取可以获取到的high water mark</li>
</ul>

<pre><code class="language-java">public interface Extractor&lt;S, D&gt; extends Closeable {

  public S getSchema() throws IOException;

  public D readRecord(@Deprecated D reuse) throws DataRecordException, IOException;

  public long getExpectedRecordCount();

  @Deprecated
  public long getHighWatermark();
}
</code></pre>

<h2 id="toc_3">四: QueryBasedExtractor</h2>

<p>实际上QueryBasedExtractor已经通过ProtocolSpecificLayer的接口实现了Extractor的接口功能。</p>

<p>比如readRecord通过getIterator()来实现迭代器从而获取一条条record。其中getRecordSetFromSourceApi和getRecordSet就是ProtocolSpecificLayer的接口。如此后续要继承QueryBasedExtractor就必须实现ProtocolSpecificLayer的接口。</p>

<p>getRecordSetFromSourceApi和getRecordSet是通过SOURCE_QUERYBASED_IS_SPECIFIC_API_ACTIVE这个配置项来选择的。</p>

<pre><code class="language-java">/**
 * Get iterator from protocol specific api if is.specific.api.active is false
 * Get iterator from source specific api if is.specific.api.active is true
 * @return iterator
 */
private Iterator&lt;D&gt; getIterator()
    throws DataRecordException, IOException {
  if (Boolean.valueOf(this.workUnit.getProp(ConfigurationKeys.SOURCE_QUERYBASED_IS_SPECIFIC_API_ACTIVE))) {
    return this.getRecordSetFromSourceApi(this.schema, this.entity, this.workUnit, this.predicateList);
  }
  return this.getRecordSet(this.schema, this.entity, this.workUnit, this.predicateList);
}
</code></pre>

<p>ProtocolSpecificLayer的接口主要是获取数据源的record schema，record数量, data type, 以及获取record等。</p>

<pre><code class="language-java">public interface ProtocolSpecificLayer&lt;S, D&gt; {
  public void extractMetadata(String schema, String entity, WorkUnit workUnit)
      throws SchemaException, IOException;

  public long getMaxWatermark(String schema, String entity, String watermarkColumn,
      List&lt;Predicate&gt; snapshotPredicateList, String watermarkSourceFormat)
      throws HighWatermarkException;

  public long getSourceCount(String schema, String entity, WorkUnit workUnit, List&lt;Predicate&gt; predicateList)
      throws RecordCountException;

  public Iterator&lt;D&gt; getRecordSet(String schema, String entity, WorkUnit workUnit, List&lt;Predicate&gt; predicateList)
      throws DataRecordException, IOException;

  public String getWatermarkSourceFormat(WatermarkType watermarkType);
  ...

  public Map&lt;String, String&gt; getDataTypeMap();

  public Iterator&lt;D&gt; getRecordSetFromSourceApi(String schema, String entity, WorkUnit workUnit,
      List&lt;Predicate&gt; predicateList)
      throws IOException;
}
</code></pre>

<h2 id="toc_4">五: JdbcExtractor 和 MysqlExtractor</h2>

<p>JdbcExtractor的情况跟QueryBasedExtractor类似, 它继承了QueryBasedExtractor,SourceSpecificLayer,JdbcSpecificLayer, 通过JdbcSpecificLayer和SourceSpecificLayer的接口来实现QueryBasedExtractor中未实现的接口。</p>

<p>而且JdbcExtractor自动将jdbc的数据转换成了json格式。</p>

<p>MysqlExtractor又最后实现了剩余的接口。</p>

<h2 id="toc_5">六: 总结</h2>

<p>由于代码比较多, 但逻辑比较简单，所以对Extractor的介绍就简单掠过了。</p>

<h3 id="toc_6">本文完</h3>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-extractor">http://lamborryan.github.io/gobblin-extractor</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gobblin系列(7)之Source源码分析]]></title>
    <link href="www.lamborryan.com/15155071664887.html"/>
    <updated>2018-01-09T22:12:46+08:00</updated>
    <id>www.lamborryan.com/15155071664887.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">一.简介</a>
</li>
<li>
<a href="#toc_1">三.AbstractSource</a>
</li>
<li>
<a href="#toc_2">四.QueryBasedSource</a>
<ul>
<li>
<a href="#toc_3">4.1. getLatestWatermarkFromMetadata</a>
</li>
<li>
<a href="#toc_4">4.2. Partitioner</a>
</li>
<li>
<a href="#toc_5">4.3. 总结</a>
</li>
</ul>
</li>
<li>
<a href="#toc_6">五.MysqlSource</a>
</li>
<li>
<a href="#toc_7">总结</a>
</li>
<li>
<a href="#toc_8">本文完</a>
</li>
</ul>


<h2 id="toc_0">一.简介</h2>

<p>Source在整个Gobblin任务流中负责以下三点:</p>

<ol>
<li>对数据源进行预切分获取<code>WorkUnits</code>。所谓预切分即是在不知道数据源是啥样的前提下, 划分好数据。</li>
<li>为每一个<code>task</code>生成一个<code>extractor</code>, 一般情况下一个<code>task</code>对应一个<code>WorkUnit</code>(当然也存在多对多的情况), 从而实现对数据的摄取。</li>
<li>提供<code>shutdown</code>处理机制, 即在job完成时候gobblin会回调<code>shutdown</code>函数, 我们可以在这里进行相应的逻辑处理。</li>
</ol>

<p>这些功能都是通过Source接口实现的。</p>

<span id="more"></span><!-- more -->

<pre><code class="language-java">/*
 * An interface for classes that the end users implement to work with a data source from which
 * schema and data records can be extracted.
 * An implementation of this interface should contain all the logic required to work with a specific data source. This usually includes work determination and partitioning, and details of the connection protocol to work with the data source.
 */
public interface Source&lt;S, D&gt; {

  /**
   * Get a list of WorkUnits, each of which is for extracting a portion of the data.

   * Each WorkUnit will be used instantiate a WorkUnitState that gets passed to the
   * getExtractor(WorkUnitState) method to get an Extractor for extracting schema and data records
   * from the source. The WorkUnit instance should have all the properties needed for the Extractor
   * to work.

   * Typically the list of WorkUnits for the current run is determined by taking into account the
   * list of WorkUnits from the previous run so data gets extracted incrementally. The method  
   * SourceState.getPreviousWorkUnitStates can be used to get the list of WorkUnits from the
   * previous run.
   */
  public abstract List&lt;WorkUnit&gt; getWorkunits(SourceState state);

  /**
   * Get an Extractor based on a given WorkUnitState.

   * The Extractor returned can use WorkUnitState to store arbitrary key-value pairs that will be
   * persisted to the state store and loaded in the next scheduled job run.
   */
  public abstract Extractor&lt;S, D&gt; getExtractor(WorkUnitState state)
      throws IOException;

  /**
   * This method is called once when the job completes. Properties (key-value pairs) added to the
   * input SourceState instance will be persisted and available to the next scheduled job run
   * through the method getWorkunits(SourceState). If there is no cleanup or reporting required for
   * a particular implementation of this interface, then it is acceptable to have a default
   * implementation of this method.
   */
  public abstract void shutdown(SourceState state);
}
</code></pre>

<p>所有的数据源都是基于Source接口实现的, 通过继承并实现这三个方法我们就可以实现自己的Source了。</p>

<p>下图是 gobblin-0.6.2自带的Source的子类。</p>

<p><img src="media/15155071664887/gobblin-source-1.png" alt="gobblin-source-1"/></p>

<p>其中</p>

<ol>
<li><code>SimpleJsonSource</code>和<code>WikipediaSource</code>都是自带的Source example</li>
<li><code>SourceDecorator</code>是Source的适配器, Gobblin-Runtime对source的调用都是通过<code>SourceDecorator</code>实现的。</li>
<li>复杂点的Source都是从<code>AbstractSource</code>, <code>AbstractSource</code>有啥作用, 它加入了对上一个job的<code>WorkUnits</code>处理, 如果上一个job周期内有<code>WorkUnits</code>处理失败了，这些<code>WorkUnits</code>就会加入到本次<code>WorkUnits</code>中，具体过程待我下节慢慢讲来。</li>
</ol>

<p>目前使用较多的数据源主要是<code>MysqlSource</code>和<code>KafkaSimpleSource</code>。</p>

<p>本文主要以<code>AbstractSource</code>-&gt;<code>QueryBasedSource</code>－&gt;<code>MysqlSource</code>这一继承关系为例来介绍Gobblin是如何实现Source的。由于关于<code>Extractor</code>将会在下篇文章中单独介绍, 因此本文主要介绍Source的<code>getWorkunits()</code>。</p>

<h2 id="toc_1">三.AbstractSource</h2>

<p>Gobblin在获取WorkUnits时候不但会根据water marks来切分当前job的WorkUnits, 而且也会根据SourceState中获取上一个job的运行状态并根据策略配置选择是否要把上一个job的WorkUnits也加进去。(关于SourceState的介绍请看<a href="http://lamborryan.github.io/gobblin-state/">《Gobblin系列六之State》</a>)</p>

<p>因此AbstractSource就是在Source的基础上增加了获取上次job中需要在本次job重新运行的WorkUnits的方法。</p>

<blockquote>
<p>We use two keys for configuring work unit retries. The first one specifies whether work unit retries are enabled or not. This is for individual jobs or a group of jobs that following the same rule for work unit retries. The second one that is more advanced is for specifying a retry policy. This one is particularly useful for being a global policy for a group of jobs that have different job commit policies and want work unit retries only for a specific job commit policy. The first one probably is sufficient for most jobs that only need a way to enable/disable work unit retries. The second one gives users more flexibilities.</p>
</blockquote>

<p>关于WorkUnitRetryPolicy策略有以下几种:</p>

<ul>
<li><code>WorkUnitRetryPolicy.ALWAYS</code>: 总会对失败或者异常的work units进行retry, 不管采用了何种提交策略。</li>
<li><code>WorkUnitRetryPolicy.ONPARTIAL</code>: 只有当提交策略是COMMIT_ON_PARTIAL_SUCCESS时候才会失败或者异常的work units进行retry.
该选项往往用在对具有不同提交策略的job group上,做为全局的Retry策略。</li>
<li><code>WorkUnitRetryPolicy.ONFULL</code>: 只有当提交策略是COMMIT_ON_FULL_SUCCESS时候才会失败或者异常的work units进行retry.
该选项往往用在对具有不同提交策略的job group上,做为全局的Retry策略。</li>
<li><code>WorkUnitRetryPolicy.NEVER</code>: 从不对失败或者异常的work units进行retry.</li>
</ul>

<pre><code class="language-java">protected List&lt;WorkUnitState&gt; getPreviousWorkUnitStatesForRetry(SourceState state) {
  * * *
  // 获取retry策略
  WorkUnitRetryPolicy workUnitRetryPolicy;
  if (state.contains(ConfigurationKeys.WORK_UNIT_RETRY_POLICY_KEY)) {
    // Use the given work unit retry policy if specified
    workUnitRetryPolicy = WorkUnitRetryPolicy.forName(state.getProp(ConfigurationKeys.WORK_UNIT_RETRY_POLICY_KEY));
  } else {
    // 根据WORK_UNIT_RETRY_ENABLED_KEY这个配置来决定是否打开WorkUnitRetryPolicy策略
    boolean retryFailedWorkUnits = state.getPropAsBoolean(ConfigurationKeys.WORK_UNIT_RETRY_ENABLED_KEY, true);
    workUnitRetryPolicy = retryFailedWorkUnits ? WorkUnitRetryPolicy.ALWAYS : WorkUnitRetryPolicy.NEVER;
  }

  // 如果是never策略则返回空的workunit
  if (workUnitRetryPolicy == WorkUnitRetryPolicy.NEVER) {
    return ImmutableList.of();
  }

  List&lt;WorkUnitState&gt; previousWorkUnitStates = Lists.newArrayList();
  // 获取上一个job的没有成功的workunit。
  for (WorkUnitState workUnitState : state.getPreviousWorkUnitStates()) {
    if (workUnitState.getWorkingState() != WorkUnitState.WorkingState.COMMITTED) {
      if (state.getPropAsBoolean(ConfigurationKeys.OVERWRITE_CONFIGS_IN_STATESTORE,
          ConfigurationKeys.DEFAULT_OVERWRITE_CONFIGS_IN_STATESTORE)) {
        // We need to make a copy here since getPreviousWorkUnitStates returns ImmutableWorkUnitStates
        // for which addAll is not supported
        WorkUnitState workUnitStateCopy = new WorkUnitState(workUnitState.getWorkunit());
        workUnitStateCopy.addAll(workUnitState);
        workUnitStateCopy.overrideWith(state);
        previousWorkUnitStates.add(workUnitStateCopy);
      } else {
        previousWorkUnitStates.add(workUnitState);
      }
    }
  }

  // 如果是always策略, 则直接返回上一个job所有失败的workunits
  if (workUnitRetryPolicy == WorkUnitRetryPolicy.ALWAYS) {
    return previousWorkUnitStates;
  }

  // 获取提交策略，默认是全部提交。
  JobCommitPolicy jobCommitPolicy = JobCommitPolicy
      .forName(state.getProp(ConfigurationKeys.JOB_COMMIT_POLICY_KEY, ConfigurationKeys.DEFAULT_JOB_COMMIT_POLICY));

  // 根据提交策略和retry策略来决定是否需要retry上一个job失败的workunits
  if ((workUnitRetryPolicy == WorkUnitRetryPolicy.ON_COMMIT_ON_PARTIAL_SUCCESS
      &amp;&amp; jobCommitPolicy == JobCommitPolicy.COMMIT_ON_PARTIAL_SUCCESS)
      || (workUnitRetryPolicy == WorkUnitRetryPolicy.ON_COMMIT_ON_FULL_SUCCESS
          &amp;&amp; jobCommitPolicy == JobCommitPolicy.COMMIT_ON_FULL_SUCCESS)) {
    return previousWorkUnitStates;
  } else {
    // Return an empty list if job commit policy and work unit retry policy do not match
    return ImmutableList.of();
  }
}
</code></pre>

<p>由代码可以看出, 对于上一个失败的workunits, 要么全部retry, 要么都不retry, 在颗粒度比较粗。</p>

<p>同时AbstractSource还会生成Extract State. 相同的namespace和table具有相同的Extract。比如kafka sourc, 虽然只是一次job, 但是有可能因为存在多个topic从而产生了不同的Extract, 即每一个top的Extract id不同。而Extract不同的一个好处是可以使用不同的发布策略。</p>

<pre><code class="language-java">public Extract createExtract(TableType type, String namespace, String table) {
    return this.extractFactory.getUniqueExtract(type, namespace, table);
}
</code></pre>

<h2 id="toc_2">四.QueryBasedSource</h2>

<p>QueryBasedSource在AbstractSource基础上又实现了query－based的getWorkunits， 已经具有很鲜明的sql特点了。<br/>
本小节主要介绍QueryBasedSource如何通过getWorkunits来获取WorkUnits.</p>

<p>QueryBasedSource的getWorkunits需要解决以下几个问题:</p>

<ul>
<li>怎么获取上一个job的Latest Water mark, 从而可以做为本次job的low Water mark</li>
<li>怎么进行partition</li>
</ul>

<p>因此分为两小节来分别介绍。</p>

<h3 id="toc_3">4.1. getLatestWatermarkFromMetadata</h3>

<ul>
<li>如果commit policy是full且有task失败了, 则Latest Water mark是所有WorkUnits中最小的low water mark。</li>
<li>如果commit policy是full且所有task成功, 则Latest Water mark是所有WorkUnits中最大的high water mark。</li>
<li>如果commit policy不是full且有task成功, 则Latest Water mark是所有成功的WorkUnits中最大的high water mark。失败的task由retry policy控制。</li>
<li>如果commit policy不是full且所有task都失败, 则Latest Water mark是所有WorkUnits中最小的low water mark。</li>
</ul>

<blockquote>
<p>这里我有疑惑: 如果设置了retry policy = JobCommitPolicy.COMMIT_ON_FULL_SUCCESS, retry policy会把上一个job的failed workunit加入到新job的workunits。 而getLatestWatermarkFromMetadata又会计算上一个job的最小的watermark，从而再次计算这些workunit。使得上一job的workunits重新跑两次。</p>
</blockquote>

<pre><code class="language-java">private long getLatestWatermarkFromMetadata(SourceState state) {
   ...
   boolean hasFailedRun = false;
   boolean isCommitOnFullSuccess = false;
   boolean isDataProcessedInPreviousRun = false;

   JobCommitPolicy commitPolicy = JobCommitPolicy
       .forName(state.getProp(ConfigurationKeys.JOB_COMMIT_POLICY_KEY, ConfigurationKeys.DEFAULT_JOB_COMMIT_POLICY));
   if (commitPolicy == JobCommitPolicy.COMMIT_ON_FULL_SUCCESS) {
     isCommitOnFullSuccess = true;
   }

   for (WorkUnitState workUnitState : previousWorkUnitStates) {
     long processedRecordCount = 0;
     if (workUnitState.getWorkingState() == WorkingState.FAILED
         || workUnitState.getWorkingState() == WorkingState.CANCELLED
         || workUnitState.getWorkingState() == WorkingState.RUNNING
         || workUnitState.getWorkingState() == WorkingState.PENDING) {
       hasFailedRun = true;
     } else {
       processedRecordCount = workUnitState.getPropAsLong(ConfigurationKeys.EXTRACTOR_ROWS_EXPECTED);
       if (processedRecordCount != 0) {
         isDataProcessedInPreviousRun = true;
       }
     }

     // Consider high water mark of the previous work unit, if it is
     // extracted any data
     if (processedRecordCount != 0) {
       previousWorkUnitStateHighWatermarks.add(workUnitState.getHighWaterMark());
     }

     previousWorkUnitLowWatermarks.add(this.getLowWatermarkFromWorkUnit(workUnitState));
   }

   // If commit policy is full and it has failed run, get latest water mark
   // as
   // minimum of low water marks from previous states.
   if (isCommitOnFullSuccess &amp;&amp; hasFailedRun) {
     long previousLowWatermark = Collections.min(previousWorkUnitLowWatermarks);

     WorkUnitState previousState = previousWorkUnitStates.get(0);
     ExtractType extractType =
         ExtractType.valueOf(previousState.getProp(ConfigurationKeys.SOURCE_QUERYBASED_EXTRACT_TYPE).toUpperCase());

     // add backup seconds only for snapshot extracts but not for appends
     if (extractType == ExtractType.SNAPSHOT) {
       int backupSecs = previousState.getPropAsInt(ConfigurationKeys.SOURCE_QUERYBASED_LOW_WATERMARK_BACKUP_SECS, 0);
       String watermarkType = previousState.getProp(ConfigurationKeys.SOURCE_QUERYBASED_WATERMARK_TYPE);
       latestWaterMark = this.addBackedUpSeconds(previousLowWatermark, backupSecs, watermarkType);
     } else {
       latestWaterMark = previousLowWatermark;
     }
   }

   // If commit policy is full and there are no failed tasks or commit
   // policy is partial,
   // get latest water mark as maximum of high water marks from previous
   // tasks.
   else {
     if (isDataProcessedInPreviousRun) {
       latestWaterMark = Collections.max(previousWorkUnitStateHighWatermarks);
     } else {
       latestWaterMark = Collections.min(previousWorkUnitLowWatermarks);
     }
   }

   return latestWaterMark;
 }
</code></pre>

<h3 id="toc_4">4.2. Partitioner</h3>

<p>Partitioner 的作用就是根据latestWaterMark来对数据进行partition, 并得到WorkUnits. Partition过程涉及到以下几个变量:</p>

<ul>
<li>interval, partition时候的最小单位, 由source.querybased.partition.interval获取。</li>
<li>maxPartitions, partition的最大个数, 由配置source.max.number.of.partitions获取。</li>
<li>lowWatermark, 根据previousWatermark(latestWaterMark)获取partition的左边界。</li>
<li>highWatermark, 计算partition的右边界。</li>
<li>source.querybased.watermark.type决定了是以哪种类型进行partition。</li>
</ul>

<p>如果lowWatermark或者highWatermark等于DEFAULT_WATERMARK_VALUE, 则只会形成一个partition。</p>

<pre><code class="language-java">public HashMap&lt;Long, Long&gt; getPartitions(long previousWatermark) {
   HashMap&lt;Long, Long&gt; defaultPartition = new HashMap&lt;Long, Long&gt;();
   ...
   // extract type 比如snapshot等
   ExtractType extractType =
       ExtractType.valueOf(this.state.getProp(ConfigurationKeys.SOURCE_QUERYBASED_EXTRACT_TYPE).toUpperCase());
    // watermarkType 类型 比如 timestamp date hour simple
   WatermarkType watermarkType =
       WatermarkType.valueOf(this.state.getProp(ConfigurationKeys.SOURCE_QUERYBASED_WATERMARK_TYPE,
           ConfigurationKeys.DEFAULT_WATERMARK_TYPE).toUpperCase());
   // 分区步长,最小单位
   int interval =
       this.getUpdatedInterval(this.state.getPropAsInt(ConfigurationKeys.SOURCE_QUERYBASED_PARTITION_INTERVAL, 0),
           extractType, watermarkType);
   int sourceMaxAllowedPartitions = this.state.getPropAsInt(ConfigurationKeys.SOURCE_MAX_NUMBER_OF_PARTITIONS, 0);
   // 最大可以分区的个数
   int maxPartitions =
       (sourceMaxAllowedPartitions != 0 ? sourceMaxAllowedPartitions
           : ConfigurationKeys.DEFAULT_MAX_NUMBER_OF_PARTITIONS);

   WatermarkPredicate watermark = new WatermarkPredicate(null, watermarkType);
   int deltaForNextWatermark = watermark.getDeltaNumForNextWatermark();

   // 可以分区的最小watermark
   long lowWatermark = this.getLowWatermark(extractType, watermarkType, previousWatermark, deltaForNextWatermark);
   // 可以分区的最大watermark
   long highWatermark = this.getHighWatermark(extractType, watermarkType);
   // 如果最小watermark或者最大watermark为－1, 则只有一个分区
   if (lowWatermark == ConfigurationKeys.DEFAULT_WATERMARK_VALUE
       || highWatermark == ConfigurationKeys.DEFAULT_WATERMARK_VALUE) {
     defaultPartition.put(lowWatermark, highWatermark);
     return defaultPartition;
   }
   // 根据相应的watertype进行分区, 实际上调用的是watermark的getIntervals
   return watermark.getPartitions(lowWatermark, highWatermark, interval, maxPartitions);
 }

</code></pre>

<p>这里要介绍下source.querybased.watermark.type这个配置, 它决定了是以哪种类型来进行partition。默认支持TIMESTAMP, DATE, HOUR, SIMPLE. 所谓的SIMPLE, 其实就是整数, Gobblin会根据这个type来决定哪种watermark。</p>

<pre><code class="language-java">public WatermarkPredicate(String watermarkColumn, WatermarkType watermarkType) {
    super();
    this.watermarkColumn = watermarkColumn;
    this.watermarkType = watermarkType;

    switch (watermarkType) {
    case TIMESTAMP:
      this.watermark = new TimestampWatermark(watermarkColumn, DEFAULT_WATERMARK_VALUE_FORMAT);
      break;
    case DATE:
      this.watermark = new DateWatermark(watermarkColumn, DEFAULT_WATERMARK_VALUE_FORMAT);
      break;
    case HOUR:
      this.watermark = new HourWatermark(watermarkColumn, DEFAULT_WATERMARK_VALUE_FORMAT);
      break;
    case SIMPLE:
      this.watermark = new SimpleWatermark(watermarkColumn, DEFAULT_WATERMARK_VALUE_FORMAT);
      break;
    default:
      this.watermark = new SimpleWatermark(watermarkColumn, DEFAULT_WATERMARK_VALUE_FORMAT);
      break;
    }
}
</code></pre>

<p>假设我们选择了TIMESTAMP, 则gobblin会实例化TimestampWatermark来进行partition。</p>

<pre><code class="language-java">synchronized public HashMap&lt;Long, Long&gt; getIntervals(long lowWatermarkValue, long highWatermarkValue, long partitionInterval, int maxIntervals) {
    ...
    HashMap&lt;Long, Long&gt; intervalMap = new HashMap&lt;Long, Long&gt;();
    Date startTime = new Date(lowWatermark);
    Date endTime = new Date(highWatermark);
    LOG.debug(&quot;Sart time:&quot; + startTime + &quot;; End time:&quot; + endTime);
    long lwm;
    long hwm;
    while (startTime.getTime() &lt;= endTime.getTime()) {
      lwm = Long.parseLong(INPUTFORMATPARSER.format(startTime));
      calendar.setTime(startTime);
      calendar.add(Calendar.HOUR, (int) interval);
      nextTime = calendar.getTime();
      hwm = Long.parseLong(INPUTFORMATPARSER.format(nextTime.getTime() &lt;= endTime.getTime() ? nextTime : endTime));
      intervalMap.put(lwm, hwm);
      LOG.debug(&quot;Partition - low:&quot; + lwm + &quot;; high:&quot; + hwm);
      calendar.add(Calendar.SECOND, deltaForNextWatermark);
      startTime = calendar.getTime();
    }

    return intervalMap;
}

</code></pre>

<p>需要说明一点就是, 如果watertype是timestamp,date,hour的highwatermark是当前时间, 如果是simple且snapshot的话, highwatermark是－1, 也就是说如果是simple的话只会有一个partition。</p>

<h3 id="toc_5">4.3. 总结</h3>

<p>最后回顾下getWorkunits的过程</p>

<pre><code class="language-java">public List&lt;WorkUnit&gt; getWorkunits(SourceState state) {
    ...
    // 获取上一个job的latest watermark
    long previousWatermark = this.getLatestWatermarkFromMetadata(state);

    // 根据latest watermark进行partition,并作排序
    Map&lt;Long, Long&gt; sortedPartitions = Maps.newTreeMap();
    sortedPartitions.putAll(new Partitioner(state).getPartitions(previousWatermark));

    // Use extract table name to create extract
    SourceState partitionState = new SourceState();
    partitionState.addAll(state);
    Extract extract = partitionState.createExtract(tableType, nameSpaceName, extractTableName);

    // Setting current time for the full extract
    if (Boolean.valueOf(state.getProp(ConfigurationKeys.EXTRACT_IS_FULL_KEY))) {
      extract.setFullTrue(System.currentTimeMillis());
    }

    // 将各paritions的watermark写入到workunits
    for (Entry&lt;Long, Long&gt; entry : sortedPartitions.entrySet()) {
      partitionState.setProp(ConfigurationKeys.WORK_UNIT_LOW_WATER_MARK_KEY, entry.getKey());
      partitionState.setProp(ConfigurationKeys.WORK_UNIT_HIGH_WATER_MARK_KEY, entry.getValue());
      workUnits.add(partitionState.createWorkUnit(extract));
    }

    // 将上一个job失败需要retry的workunit添加到本job的workunit中
    List&lt;WorkUnit&gt; previousWorkUnits = this.getPreviousWorkUnitsForRetry(state);
    LOG.info(&quot;Total number of incomplete tasks from the previous run: &quot; + previousWorkUnits.size());
    workUnits.addAll(previousWorkUnits);

    return workUnits;
  }
</code></pre>

<h2 id="toc_6">五.MysqlSource</h2>

<p>最后MysqlSource只实现了getExtractor接口，即返回一个getExtractor对象.</p>

<pre><code class="language-java">public class MysqlSource extends QueryBasedSource&lt;JsonArray, JsonElement&gt; {
    private static final Logger LOG = LoggerFactory.getLogger(MysqlSource.class);

    public Extractor&lt;JsonArray, JsonElement&gt; getExtractor(WorkUnitState state)
      throws IOException {
        Extractor&lt;JsonArray, JsonElement&gt; extractor = null;
        try {
          extractor = new MysqlExtractor(state).build();
        } catch (ExtractPrepareException e) {
          LOG.error(&quot;Failed to prepare extractor: error - &quot; + e.getMessage());
          throw new IOException(e);
        }
        return extractor;
    }
}
</code></pre>

<h2 id="toc_7">总结</h2>

<p>本文主要介绍了Source的几个重要功能, 以MysqlSource为例介绍了Source是如何getWorkunits的, 在这过程中又结合watermark简单描述了gobblin的retry策略。</p>

<h2 id="toc_8">本文完</h2>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-source">http://lamborryan.github.io/gobblin-source</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gobblin系列(6)之State]]></title>
    <link href="www.lamborryan.com/15155068855798.html"/>
    <updated>2018-01-09T22:08:05+08:00</updated>
    <id>www.lamborryan.com/15155068855798.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">一. 简介</a>
</li>
<li>
<a href="#toc_1">二. SourceState, JobState, DatasetState</a>
<ul>
<li>
<a href="#toc_2">2.1.SourceState</a>
</li>
<li>
<a href="#toc_3">2.2.JobState</a>
</li>
<li>
<a href="#toc_4">2.3.DatasetState</a>
</li>
</ul>
</li>
<li>
<a href="#toc_5">三. WorkUnit, MutliWorkUnit</a>
<ul>
<li>
<a href="#toc_6">3.1.WorkUnit</a>
</li>
<li>
<a href="#toc_7">3.2.MutliWorkUnit</a>
</li>
</ul>
</li>
<li>
<a href="#toc_8">四. WorkUnitState, TaskState</a>
<ul>
<li>
<a href="#toc_9">4.1.WorkUnitState</a>
</li>
<li>
<a href="#toc_10">4.2.TaskState</a>
</li>
</ul>
</li>
<li>
<a href="#toc_11">五. Extract</a>
</li>
<li>
<a href="#toc_12">六. 运行过程转换</a>
</li>
<li>
<a href="#toc_13">七. 总结</a>
</li>
</ul>


<h2 id="toc_0">一. 简介</h2>

<p>Gobblin实在是有太多的state了, 比如SourceState, JobState, DatasetState, WorkUnit等等. 而这些State又跟整个Gobblin的各个阶段密切联系, 所以我独立出一篇文章来理顺下这些State。</p>

<span id="more"></span><!-- more -->

<p>本文借鉴了这篇文档<a href="http://gobblin.readthedocs.org/en/latest/user-guide/State-Management-and-Watermarks/#gobblin-state-deep-dive">《gobblin-state-deep-dive》</a></p>

<p>下图是Gobblin的类关系, 通过它我们可以对整个State体系有个初步了解:</p>

<p><img src="media/15155068855798/gobblin-state-1.png" alt="gobblin-state-1"/></p>

<p>基类<code>State</code>是<code>Properties</code>的封装, 并提供了对它的一系列方法。</p>

<h2 id="toc_1">二. SourceState, JobState, DatasetState</h2>

<h3 id="toc_2">2.1.SourceState</h3>

<p>SourceState主要有几个任务:</p>

<ol>
<li>包含当前job的配置文件的配置</li>
<li>包含上一个job在StateStore存储下来的State</li>
<li>为Source提供根据Extract生成WorkUnit的方法</li>
<li>提供生成Extract的方法</li>
</ol>

<p>因此SourceState主要作用阶段在source.</p>

<pre><code class="language-java">public class SourceState extends State {
    * * *
    /* 上一个job的state */
    private final Map&lt;String, SourceState&gt; previousDatasetStatesByUrns;
    private final List&lt;WorkUnitState&gt; previousWorkUnitStates = Lists.newArrayList();

    /* 创建Extract Statte */
    public synchronized Extract createExtract(Extract.TableType type, String namespace, String table) {
      Extract extract = new Extract(this, type, namespace, table);
      while (EXTRACT_SET.contains(extract)) {
        if (Strings.isNullOrEmpty(extract.getExtractId())) {
          extract.setExtractId(DTF.print(new DateTime()));
        } else {
          DateTime extractDateTime = DTF.parseDateTime(extract.getExtractId());
          extract.setExtractId(DTF.print(extractDateTime.plusSeconds(1)));
        }
      }
      EXTRACT_SET.add(extract);
      return extract;
    }

    /* 根据State创建WorkUnit Statte */
    public WorkUnit createWorkUnit(Extract extract) {
      return new WorkUnit(this, extract);
    }

    * * *
}
</code></pre>

<h3 id="toc_3">2.2.JobState</h3>

<p>JobState在SourceState基础上更进了一步, 它不但包含了SourceState的配置和功能, 更加入了job运行时的配置参数, 比如job ID, 开始时间, 结束时间, 以及job的运行状态等, 以及每个task的TaskState.</p>

<pre><code class="language-java">
public class JobState extends SourceState {

  /**
   * Job运行状态
   */
  public enum RunningState {
    PENDING, RUNNING, SUCCESSFUL, COMMITTED, FAILED, CANCELLED
  }

  private String jobName;   // job运行名字
  private String jobId;     // job id
  private long startTime = 0; // job开始时间
  private long endTime = 0; // job结束时间
  private long duration = 0; // 持续时间
  private RunningState state = RunningState.PENDING; //Job运行状态
  private int taskCount = 0; // task个数
  private final Map&lt;String, TaskState&gt; taskStates = Maps.newLinkedHashMap();// 所有task状态

}
</code></pre>

<p>因为JobState基本上包含了所有job的运行信息, 所以它的生命周期就是完整的job的生命周期, 特别是在metrics输出信息。</p>

<h3 id="toc_4">2.3.DatasetState</h3>

<p>DatasetState在JobState的基础上添加了dataset.urn属性以此来区分不同的dataset。目前主要用在<code>FsDatasetStateStore</code></p>

<h2 id="toc_5">三. WorkUnit, MutliWorkUnit</h2>

<h3 id="toc_6">3.1.WorkUnit</h3>

<p>WorkUnit主要包含以下几个内容:</p>

<ol>
<li>包含State即SourceState的所有properties, 这是因为WorkUnit是由Source的<code>getWorkunits(SourceState)</code>生成的</li>
<li>包含low watermark和high watermark的数据, 即摄取的数据的摄取范围</li>
<li>包含Extractor，摄取器.</li>
</ol>

<pre><code class="language-java">
public WorkUnit(SourceState state, Extract extract) {
  // Values should only be null for deserialization
  if (state != null) {
    super.addAll(state);
  }

  if (extract != null) {
    this.extract = extract;
  } else {
    this.extract = new Extract(null, null, null, null);
  }
}

public void setLowWaterMark(long lowWaterMark) {
  setProp(ConfigurationKeys.WORK_UNIT_LOW_WATER_MARK_KEY, lowWaterMark);
}

public void setHighWaterMark(long highWaterMark) {
  setProp(ConfigurationKeys.WORK_UNIT_HIGH_WATER_MARK_KEY, highWaterMark);
}
</code></pre>

<p>WorkUnit由Source的getWorkunits生成, 主要是为了记录不同task应该摄取哪部分数据.</p>

<h3 id="toc_7">3.2.MutliWorkUnit</h3>

<p>MutliWorkUnit继承了WorkUnit, 其实质则是对多个WorkUnit进行了封装以便后续运行在一个task中, 如果MutliWorkUnit包含了所有的WorkUnits, 那么一个job就只会对应一个task。</p>

<pre><code class="language-java">public class MultiWorkUnit extends WorkUnit {

  private final List&lt;WorkUnit&gt; workUnits = Lists.newArrayList();

  @Deprecated
  public MultiWorkUnit() {
    super();
  }

  * * *
}
</code></pre>

<p>MutliWorkUnit的出现很好对source的partition进行了补充, 使得它在负载均衡上面得到了很好的提升。如果没有MutliWorkUnit, 那么mapreduce模式下由于partition的不均衡很容易造成数据倾斜. 而MutliWorkUnit的存在使得我们可以通过合并小的WorkUnit的平衡每个map的数据, 降低数据倾斜的风险。</p>

<h2 id="toc_8">四. WorkUnitState, TaskState</h2>

<h3 id="toc_9">4.1.WorkUnitState</h3>

<p>WorkUnitState不但包含了WorkUnit的所有配置, 也包含了WorkUnit的运行状态以及非常重要的actual high watermark。</p>

<pre><code class="language-java">public class WorkUnitState extends State {
    public enum WorkingState {
    PENDING,
    RUNNING,
    SUCCESSFUL,
    COMMITTED,
    FAILED,
    CANCELLED
    }
    private WorkUnit workunit;
    public WorkUnitState(WorkUnit workUnit) {
        this.workunit = workUnit;
    }
    public void setActualHighWatermark(Watermark watermark) {
        setProp(ConfigurationKeys.WORK_UNIT_STATE_ACTUAL_HIGH_WATER_MARK_KEY, watermark.toJson().toString());
    }
}
</code></pre>

<blockquote>
<p>setActualHighWatermark 是在Extractor中初始化时候设置的，它必须赶在readRecord调用前进行set。</p>
</blockquote>

<h3 id="toc_10">4.2.TaskState</h3>

<p>TaskState在WorkUnitState的基础上加入了task有关的一些信息, 比如task id, task name, start time, end time 等。生命周期贯穿了整个task，类似于job task, 不同之处前者在task level，后者在task level。因此TaskState也会在metrix存储相应的运行信息。</p>

<pre><code class="language-java">
public class TaskState extends WorkUnitState {
    * * *
    private String jobId;
    private String taskId;
    private long startTime = 0;
    private long endTime = 0;
    private long duration;

    public TaskState(WorkUnitState workUnitState) {
        // Since getWorkunit() returns an immutable WorkUnit object,
        // the WorkUnit object in this object is also immutable.
        super(workUnitState.getWorkunit());
        addAll(workUnitState);
        this.jobId = workUnitState.getProp(ConfigurationKeys.JOB_ID_KEY);
        this.taskId = workUnitState.getProp(ConfigurationKeys.TASK_ID_KEY);
        this.setId(this.taskId);
    }

    * * *
}

</code></pre>

<h2 id="toc_11">五. Extract</h2>

<p>Extract对接需要摄入的数据源, 它包含了需要摄入的配置信息, 比如摄入方式(snapshot-only, append-only, snapshot-append), 主键(primary keys), 需要增量的键(delta fields)等等。</p>

<p>相同namespace和table下的Extracts必须有不同的extract ID。 一个或多个WorkUnits可以分享同一个extract ID。 具有相同的extract ID的WorkUnits可以视为同一个Extract的组成部分, 以便使用相同的发布策略。</p>

<h2 id="toc_12">六. 运行过程转换</h2>

<p>本小节主要介绍这些state在gobblin运行过程中的关系:</p>

<ul>
<li>当job开始运行时候, job launch首先会创建JobState, 它包含两部分信息, 1) 所有job的配置文件; 2) 上一个job的JobState / DatasetState, 以及其他的配置, 如每个JobState／DatasetState的 actual high watermark等</li>
<li>Job Launcher 会把JobState(以SourceState的形势)传给Souce, Source根据JobState来创建WorkUnits。当创建WorkUnits时候, JobState不会立马就加载进WorkUnits, 而是在task执行时候才会完成加载。这是因为当laucher运行在单个JVM时候,如果创建大量的WorkUnits且都是JobState copy有可能会出现oom。</li>
<li>job launcher 准备开始运行WorkUnits。</li>
<li>在standalone模式中, job launcher会把JobState添加到每一个WorkUnit, 如果配置已经在WorkUnit中则不会覆盖。对于每一个WorkUnit， job launcher都会创建一个task去运行WorkUnit，并提交所有task到TaskExecutor运行在同一个线程池中。</li>
<li>在MR模式下, job laucher会序列化JobState和每一个WorkUnit, 并被mapper所获取。</li>
</ul>

<p>此时 job launcher 会等待所有task完成。</p>

<ul>
<li>每个task对应一个workunit, 每个task包含一个TaskState。初始化时候，TaskState获取JobState以及workunit所有配置, 运行过程中, 更多的Extractor, Converter 和 Writer的配置, 比如actual high watermark, 会通过Extractor加入到TaskState。</li>
<li>当所有Task完成时候, TaskState会根据dataset.urn创建DatasetStates。当dataset的数据提交时候, job launcher就会存下DatasetState。 如果没有dataset.urn, 那么只会有单个DatasetState，并根据提交策略进行提交。</li>
</ul>

<h2 id="toc_13">七. 总结</h2>

<p>最后说下我的理解:</p>

<ul>
<li>WorkUnitState包含了WorkUnit的配置以及task运行的状态数据.</li>
<li>TaskState包含了WorkUnitState和Task的基本信息(id,start time, end time)</li>
<li>JobState包含配置文件配置, 所有task的TaskState，以及job的基础信息(id, start time, end time)。</li>
<li>在初始阶段, WorkUnits由JobState生成。</li>
</ul>

<p>本文完</p>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-state">http://lamborryan.github.io/gobblin-state</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gobblin系列(5)之Writer源码分析]]></title>
    <link href="www.lamborryan.com/15155067914960.html"/>
    <updated>2018-01-09T22:06:31+08:00</updated>
    <id>www.lamborryan.com/15155067914960.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">简介</a>
</li>
<li>
<a href="#toc_1">流程简述</a>
</li>
<li>
<a href="#toc_2">PartitionedDataWriter</a>
<ul>
<li>
<ul>
<li>
<a href="#toc_3">PartitionedDataWriter的初始化</a>
</li>
<li>
<a href="#toc_4">PartitionedDataWriter的基类</a>
</li>
<li>
<a href="#toc_5">PartitionedDataWriter的具体实现</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_6">partition</a>
</li>
<li>
<a href="#toc_7">DataWriter</a>
</li>
<li>
<a href="#toc_8">Publiser</a>
</li>
<li>
<a href="#toc_9">总结</a>
</li>
</ul>


<h2 id="toc_0">简介</h2>

<p>Gobblin的writer功能还是很强大的, 该Stage负责将record写入临时文件中。由于项目的需要, 要求把每天的kafka日志按照日期按天输出到不同的目录。所以花了一天时间研究了Writer的源码和流程。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">流程简述</h2>

<p><img src="media/15155067914960/gobblin-7.png" alt="gobblin-7"/></p>

<ul>
<li>PartitionedDataWriter是整个过程的中心，它负责链接partitioner, PartitionAwareDataWriterBuilder,和writer.</li>
<li>partitioner负责计算每一个record的partition.</li>
<li>PartitionedDataWriter会在内存中创建LoadingCache<k,v>,存放partition和writer的哈希映射，PartitionAwareDataWriterBuilder负责为那些还没存放在内存的partition创建writer。</li>
<li>writer负责进行数据落地，即对同一partition的records调用其对应的writer写入数据。</li>
</ul>

<blockquote>
<p>注意 不管有没有需要partition, Gobblin的writer都是从PartitionedDataWriter开始,可以把不需要分区这种情况理解为只有一个分区。</p>
</blockquote>

<p>接下来让我们根据源码来展开整个过程吧</p>

<h2 id="toc_2">PartitionedDataWriter</h2>

<h4 id="toc_3">PartitionedDataWriter的初始化</h4>

<p>Writer流程得从上一篇文章<a href="http://lamborryan.github.io/gobblin-runtime-view/">《Gobblin系列四之Runtime初探》</a>上谈起。<br/>
Writer是在fork.class中processRecords方法通过buildWriterIfNotPresent创建的, 那么我们先从这里开始查看源码。</p>

<pre><code class="language-java">private void buildWriterIfNotPresent() throws IOException {
  if (!this.writer.isPresent()) {
    try {
      this.writer = Optional.of(this.closer.register(buildWriter()));
    } catch (SchemaConversionException sce) {
      throw new IOException(&quot;Failed to build writer for fork &quot; + this.index, sce);
    }
  }
}
/**
 * Build a {@link gobblin.writer.DataWriter} for writing fetched data records.
 */
private DataWriter&lt;Object&gt; buildWriter()
    throws IOException, SchemaConversionException {
  DataWriterBuilder&lt;Object, Object&gt; builder = this.taskContext.getDataWriterBuilder(this.branches, this.index)
      .writeTo(Destination.of(this.taskContext.getDestinationType(this.branches, this.index), this.taskState))
      .writeInFormat(this.taskContext.getWriterOutputFormat(this.branches, this.index))
      .withWriterId(this.taskId)
      .withSchema(this.convertedSchema.orNull())
      .withBranches(this.branches)
      .forBranch(this.index);

  return new PartitionedDataWriter&lt;&gt;(builder, this.taskContext.getTaskState());
}
</code></pre>

<p>从上述代码上看出, 一切的writer都开始于PartitionedDataWriter. 看看这个名字就可以看出gobblin默认就支持分区输出, 所以心里就放松了大半, 这个功能不需要花太大精力开发了。那么接下来就是分析PartitionedDataWriter这个class了。</p>

<h4 id="toc_4">PartitionedDataWriter的基类</h4>

<p>DataWriter做为interface定义了实现writer所需要实现的方法, 而PartitionedDataWriter继承了DataWriter,</p>

<pre><code class="language-java">public interface DataWriter&lt;D&gt; extends Closeable {

  /**
   * Write a source data record in Avro format using the given converter.
   *
   * @param record data record to write
   * @throws IOException if there is anything wrong writing the record
   */
  public void write(D record)
      throws IOException;

  /**
   * Commit the data written.
   *
   * @throws IOException if there is anything wrong committing the output
   */
  public void commit()
      throws IOException;

  /**
   * Cleanup context/resources.
   *
   * @throws IOException if there is anything wrong doing cleanup.
   */
  public void cleanup()
      throws IOException;

  /**
   * Get the number of records written.
   *
   * @return number of records written
   */
  public long recordsWritten();

  /**
   * Get the number of bytes written.
   *
   * @return number of bytes written
   */
  public long bytesWritten()
      throws IOException;
}
</code></pre>

<h4 id="toc_5">PartitionedDataWriter的具体实现</h4>

<p>PartitionedDataWriter他的代码还是比较简单的, 主要分为以下几个功能:</p>

<p>1.如果配置文件指定了writer.partitioner.class这个属性, 那么就创建这个partitioner的实例, 负责对record的分区。如果没有设置该属性,就意味着不需要进行分区,所以所有的record都分在一个partitioner中。</p>

<pre><code class="language-java">if (state.contains(ConfigurationKeys.WRITER_PARTITIONER_CLASS)) {
  // 如果设置了writer.partitioner.class属性则根据该类创建partitioner
  Preconditions.checkArgument(builder instanceof PartitionAwareDataWriterBuilder,
      String.format(&quot;%s was specified but the writer %s does not support partitioning.&quot;,
          ConfigurationKeys.WRITER_PARTITIONER_CLASS, builder.getClass().getCanonicalName()));

  try {
    this.shouldPartition = true;
    // 创建dataWriterBuilder，后续生成dataWriter
    this.builder = Optional.of(PartitionAwareDataWriterBuilder.class.cast(builder));
    // 创建partitionner
    this.partitioner = Optional.of(WriterPartitioner.class.cast(
        ConstructorUtils.invokeConstructor(Class.forName(state.getProp(ConfigurationKeys.WRITER_PARTITIONER_CLASS)),
            state, builder.getBranches(), builder.getBranch())));
  } catch (ReflectiveOperationException roe) {
    throw new IOException(roe);
  }
} else {
  // 如果没有设置了writer.partitioner.class, 则用NON_PARTITIONED_WRITER_KEY来表示只有一个partitioner
  this.shouldPartition = false;
  InstrumentedDataWriterDecorator&lt;D&gt; writer =
      this.closer.register(new InstrumentedDataWriterDecorator&lt;D&gt;(builder.build(), state));
  this.partitionWriters.put(NON_PARTITIONED_WRITER_KEY, writer);
  this.partitioner = Optional.absent();
  this.builder = Optional.absent();
}
</code></pre>

<p>所以需要在.pull配置writer.partitioner.class=gobblin.core.writer.partitioner.TimeBasedJsonWriterPartitioner来告诉gobblin按照TimeBasedJsonWriterPartitioner的规则进行partition</p>

<p>2.设置分区后, 在内存中以LoadingCache<k,v>存放record的partition和其对应的writer.</p>

<pre><code class="language-java">
private final LoadingCache&lt;GenericRecord, DataWriter&lt;D&gt;&gt; partitionWriters;

this.partitionWriters = CacheBuilder.newBuilder().build(new CacheLoader&lt;GenericRecord, DataWriter&lt;D&gt;&gt;() {
      @Override
      public DataWriter&lt;D&gt; load(final GenericRecord key) throws Exception {
        return closer
            .register(new InstrumentedPartitionedDataWriterDecorator&lt;D&gt;(createPartitionWriter(key), state, key));
      }
    });
</code></pre>

<blockquote>
<p>上述代码实现了回调, 当partitionWriters.get(key)时, 如果没有key,则通过load来创建新的writer</p>
</blockquote>

<p>3.为新的record partition创建writer。</p>

<pre><code class="language-java">private DataWriter&lt;D&gt; createPartitionWriter(GenericRecord partition) throws IOException {
  if (!this.builder.isPresent()) {
    throw new IOException(&quot;Writer builder not found. This is an error in the code.&quot;);
  }
  return this.builder.get().forPartition(partition).withWriterId(this.baseWriterId + &quot;_&quot; + this.writerIdSuffix++)
      .build();
}
</code></pre>

<p>writer的创建分为两步:</p>

<ul>
<li>根据partition, 创建PartitionAwareDataWriterBuilder, 即this.builder.get().forPartition(partition)返回partition对应的PartitionAwareDataWriterBuilder</li>
<li>调用PartitionAwareDataWriterBuilder的build创建DataWriter</li>
</ul>

<pre><code class="language-java">public abstract class PartitionAwareDataWriterBuilder&lt;S, D&gt; extends DataWriterBuilder&lt;S, D&gt; {

  protected Optional&lt;GenericRecord&gt; partition = Optional.absent();

  public PartitionAwareDataWriterBuilder&lt;S, D&gt; forPartition(GenericRecord partition) {
    this.partition = Optional.fromNullable(partition);
    return this;
  }

  public abstract boolean validatePartitionSchema(Schema partitionSchema);
}

</code></pre>

<p>关于PartitionAwareDataWriterBuilder的介绍请看文档<a href="https://github.com/linkedin/gobblin/wiki/Partitioned%20Writers">&lt;Partitioned Writers &gt;</a> ,结合它来看本文更容易理解。</p>

<p>例如以下的simpleWriterBuilder:</p>

<pre><code class="language-java">public class SimpleDataWriterBuilder extends FsDataWriterBuilder&lt;String, byte[]&gt; {
  @Override
  public DataWriter&lt;byte[]&gt; build() throws IOException {
    return new SimpleDataWriter(this, this.destination.getProperties());
  }
}
</code></pre>

<p>所以需要.pull文件中指定writer.builder.class=gobblin.writer.SimpleDataWriterBuilder来告诉gobblin我需要通过SimpleDataWriter来进行datawriter</p>

<p>4.writer 和 commit</p>

<pre><code class="language-java">@Override
public void write(D record) throws IOException {
  try {

    // 使用partitioner来计算record的partition
    GenericRecord partition =
        this.shouldPartition ? this.partitioner.get().partitionForRecord(record) : NON_PARTITIONED_WRITER_KEY;

    // 根据partition获取datawriter, 如果没有相应的datawriter则创建一个新的datawriter
    DataWriter&lt;D&gt; writer = this.partitionWriters.get(partition);

    // 调用datawriter的writer进行record的writer
    writer.write(record);
  } catch (ExecutionException ee) {
    throw new IOException(ee);
  }
}

@Override
public void commit() throws IOException {
  int writersCommitted = 0;
  for (Map.Entry&lt;GenericRecord, DataWriter&lt;D&gt;&gt; entry : this.partitionWriters.asMap().entrySet()) {
    try {
      // 对所有的datawriter调用commit
      entry.getValue().commit();
      writersCommitted++;
    } catch (Throwable throwable) {
      log.error(String.format(&quot;Failed to commit writer for partition %s.&quot;, entry.getKey()), throwable);
    }
  }
  if (writersCommitted &lt; this.partitionWriters.asMap().size()) {
    throw new IOException(&quot;Failed to commit all writers.&quot;);
  }
}
</code></pre>

<p>由此可见PartitionedDataWriter的writer和commit都是根据record的partition获取其对应的writer然后进行write和commit。 只不过在进行writer的时候如果还没该partition时会调用createPartitionWriter为该partition创建相应的writer。</p>

<p>至此关于PartitionedDataWriter的代码逻辑就介绍的差不多了。</p>

<h2 id="toc_6">partition</h2>

<p>所有partition.class都继承自接口WriterPartitioner, 他实现两个功能:</p>

<pre><code class="language-java">
public interface WriterPartitioner&lt;D&gt; {

  // partition的结构,
  public Schema partitionSchema();

  // 根据record计算partition
  public GenericRecord partitionForRecord(D record);

}
</code></pre>

<p>Gobblin默认支持时间为key的分区, 它实现了一个abstract class TimeBasedWriterPartitioner, 我们只需要根据自己的需要继承这个类做相应的开发就行了。比如我的record是json格式的, 那么我需要继承得到自己的实现类TimeBasedJsonWriterPartitioner.(Gobblin通过继承TimeBasedWriterPartitioner实现了TimeBasedAvroWriterPartitioner, 即对应record格式是avro的)</p>

<p>接下来让我们看看TimeBasedWriterPartitioner是怎么实现的以上两个方法的。</p>

<p>1.partitionForRecord方法</p>

<pre><code class="language-java">
@Override
 public GenericRecord partitionForRecord(D record) {
   // 虚函数，需要我们自己写解析方法, 即根据record的格式解析出里面的时间字段。
   long timestamp = getRecordTimestamp(record);

   // 按照partitionSchema方法产生的Schema封装timestamp为GenericRecord
   GenericRecord partition = new GenericData.Record(this.schema);
   if (!Strings.isNullOrEmpty(this.writerPartitionPrefix)) {
     partition.put(PREFIX, this.writerPartitionPrefix);
   }
   if (!Strings.isNullOrEmpty(this.writerPartitionSuffix)) {
     partition.put(SUFFIX, this.writerPartitionSuffix);
   }

   if (this.timestampToPathFormatter.isPresent()) {
     String partitionedPath = getPartitionedPath(timestamp);
     partition.put(PARTITIONED_PATH, partitionedPath);
   } else {
     DateTime dateTime = new DateTime(timestamp, this.timeZone);
     switch (this.granularity) {
       case MINUTE:
         partition.put(Granularity.MINUTE.toString(), dateTime.getMinuteOfHour());
       case HOUR:
         partition.put(Granularity.HOUR.toString(), dateTime.getHourOfDay());
       case DAY:
         partition.put(Granularity.DAY.toString(), dateTime.getDayOfMonth());
       case MONTH:
         partition.put(Granularity.MONTH.toString(), dateTime.getMonthOfYear());
       case YEAR:
         partition.put(Granularity.YEAR.toString(), dateTime.getYear());
     }
   }

   return partition;
 }

 // 虚函数，需要我们自己写解析方法, 即根据record的格式解析出里面的时间字段。
 public abstract long getRecordTimestamp(D record);
</code></pre>

<p>2.partitionSchema方法</p>

<pre><code class="language-java">
this.schema = getSchema();

private Schema getSchema() {
  if (this.timestampToPathFormatter.isPresent()) {
    return getDateTimeFormatBasedSchema();
  } else {
    return getGranularityBasedSchema();
  }
}

@Override
public Schema partitionSchema() {
  return this.schema;
}

</code></pre>

<p>该段代码的意思就是根据writer.partition.granularity这个配置项来组合Schema, 比如我设置了writer.partition.granularity=DAY.就返回Granularity.DAY.toString()</p>

<p>最后附上我的实现类TimeBasedJsonWriterPartitioner怎么实现getRecordTimestamp</p>

<pre><code class="language-java">
/**
 *  Check if the partition column value is present and is a Long object. Otherwise, use current system time.
 */
private long getRecordTimestamp(Optional&lt;Object&gt; writerPartitionColumnValue) {

    return writerPartitionColumnValue.orNull()  instanceof Long ? (Long) writerPartitionColumnValue.get()
            : System.currentTimeMillis();
}

@Override
public long getRecordTimestamp(byte[] record) {

    return getRecordTimestamp(getWriterPartitionColumnValue(record));
}


/**
 * Retrieve the value of the partition column field specified by this.partitionColumns
 */
private Optional&lt;Object&gt; getWriterPartitionColumnValue(byte[] record){
    if (!this.partitionColumns.isPresent()) {
        return Optional.absent();
    }

    Optional&lt;Object&gt; fieldValue = Optional.absent();

    for (String partitionColumn : this.partitionColumns.get()) {
        JSONObject jsonObject = new JSONObject(new String(record));
        fieldValue = Optional.of(jsonObject.get(partitionColumn));
        if(fieldValue.isPresent()){
            return fieldValue;
        }
    }

    return fieldValue;
}

</code></pre>

<p>上述代码实现了以下功能:</p>

<ul>
<li>根据配置writer.partition.columns获取字段名</li>
<li>解析json格式的record, 获取writer.partition.columns字段对应的时间戳</li>
<li>如果json解析失败则返回当前时间的时间戳。</li>
</ul>

<p>比如我设置了writer.partition.columns=timestamp</p>

<blockquote>
<p>我们需要writer.partition.timezone=Asia/Shanghai这个配置来指定时区,否则会出错。</p>
</blockquote>

<h2 id="toc_7">DataWriter</h2>

<p>Gobblin默认实现了SimpleDataWriter和AvroHDFSDataWriter, 它们都继承了FsDataWriter, FsDataWriter继承了DataWriter.</p>

<p>SimpleDataWriter将byte[]格式的record写入到文件系统(本地或者hdfs), 而AvroHDFSDataWriter则将avro格式的record写入到文件系统中.</p>

<p>以SimpleDataWriter为例, record被写入到stageFile目录中。</p>

<pre><code class="language-java">@Override
public void write(byte[] record) throws IOException {
  Preconditions.checkNotNull(record);

  byte[] toWrite = record;
  if (this.recordDelimiter.isPresent()) {
    toWrite = Arrays.copyOf(record, record.length + 1);
    toWrite[toWrite.length - 1] = this.recordDelimiter.get();
  }
  if (this.prependSize) {
    long recordSize = toWrite.length;
    ByteBuffer buf = ByteBuffer.allocate(Longs.BYTES);
    buf.putLong(recordSize);
    toWrite = ArrayUtils.addAll(buf.array(), toWrite);
  }
  this.stagingFileOutputStream.write(toWrite);
  this.bytesWritten += toWrite.length;
  this.recordsWritten++;
}

</code></pre>

<blockquote>
<p>每一个partition对应自己的dataWriter, 每一个dataWriter的作用范围也只能是自己的partition。</p>
</blockquote>

<h2 id="toc_8">Publiser</h2>

<p>到这一步为止, Gobblin已经将record按timestamp进行分区并按不同的目录写入到stageFile目录中。但是整个过程还没有完整。我们需要通过Publiser把数据publish到job－output上去。</p>

<p>刚好Gobblin已经帮我们实现了基于partition的publiser TimePartitionedDataPublisher.因此加入以下配置项即可:data.publisher.type=gobblin.publisher.TimePartitionedDataPublisher</p>

<h2 id="toc_9">总结</h2>

<p>本文简单介绍了整个writer的流程, 尤其是partition writer。 并结合源码具体介绍了 PartitionedDataWriter, PartitionAwareDataWriterBuilder, partition, datawriter, publiser这几个重要模块。</p>

<p>同时介绍了我自己实现TimeBasedJsonWriterPartitioner的过程。</p>

<p>最后是完整的partition writer的配置</p>

<pre><code class="language-bash">
kafka.brokers=x15:9091

source.class=gobblin.source.extractor.extract.kafka.KafkaSimpleSource
extract.namespace=gobblin.extract.kafka

topic.whitelist=biz_stats
writer.builder.class=gobblin.writer.SimpleDataWriterBuilder
simple.writer.delimiter=\n
simple.writer.prepend.size=false
writer.file.path.type=tablename
writer.destination.type=HDFS
writer.output.format=csv
writer.partitioner.class=xiaomei.gobblin.core.writer.partitioner.TimeBasedJsonWriterPartitioner
writer.partition.level=date
writer.partition.pattern=YYYY/MM/dd
writer.partition.columns=timestamp
writer.partition.timezone=Asia/Shanghai

data.publisher.type=gobblin.publisher.TimePartitionedDataPublisher

</code></pre>

<p>本文完</p>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-state">http://lamborryan.github.io/gobblin-state</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gobblin系列(4)之Runtime初探]]></title>
    <link href="www.lamborryan.com/15155066323075.html"/>
    <updated>2018-01-09T22:03:52+08:00</updated>
    <id>www.lamborryan.com/15155066323075.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">简介</a>
</li>
<li>
<a href="#toc_1">工作流</a>
<ul>
<li>
<ul>
<li>
<a href="#toc_2">commit/publiser 和 persist</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_3">任务流</a>
<ul>
<li>
<ul>
<li>
<a href="#toc_4">Task逻辑</a>
</li>
<li>
<a href="#toc_5">Fork 逻辑</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_6">总结</a>
</li>
</ul>


<h2 id="toc_0">简介</h2>

<p>Gobblin有两个重要的包即Gobblin-core和Gobblin-runtime, 前者实现了丰富的模块组件, 后者实现了完整的运行机制, 如此构成了Gobblin的高可扩展性的特点。</p>

<p>作为Gobblin的内核, Gobblin-runtime实现了Gobblin的工作流程和任务流程。本文名为Runtime初探, 主要研究目的就是通过Gobblin-runtime来了解Gobblin的运行逻辑, 便于后续对Gobblin的灵活开发。</p>

<p>在前文<a href="http://lamborryan.github.io/gobblin-first-exploration/">《Gobblin系列一之初探》</a>中提到了Gobblin具有工作流和任务流的概念。那么本文就分为工作流和任务流两块来介绍。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">工作流</h2>

<p>所谓工作流就是指gobblin job从启动开始到结束这一个生命周期的工作流程。 这里引用<a href="http://lamborryan.github.io/gobblin-first-exploration/">《Gobblin系列一之初探》</a> 的图示.</p>

<p><img src="media/15155066323075/gobblin-2.png" alt="gobblin-2"/></p>

<p>那么本节主要通过代码阅读来加深这一幅图。 工作流的代码主要集中在AbstractJobLauncher这个虚类中。它定义了启动和运行job的框架，它有两个子类为LocalJobLauncher和MRJobLauncher, 分别对应stanalone和mapreduce这两个运行模式。</p>

<p>工作流主要逻辑都在launchJob方法内</p>

<pre><code class="language-java">    public void launchJob(JobListener jobListener) throws JobException {

        // *** 省略代码

        // 获取job锁
        if (!tryLockJob()) {
            this.eventSubmitter.submit(gobblin.metrics.event.EventNames.LOCK_IN_USE);
            throw new JobException(String.format(
              &quot;Previous instance of job %s is still running, skipping this scheduled run&quot;, this.jobContext.getJobName()));
        }
        // *** 省略代码

        // 根据配置文件内设置的Source获取WorkUnits, 这里注意source的getWorkunits方法
        TimingEvent workUnitsCreationTimer =
          this.eventSubmitter.getTimingEvent(TimingEventNames.LauncherTimings.WORK_UNITS_CREATION);
        // Generate work units of the job from the source
        Optional&lt;List&lt;WorkUnit&gt;&gt; workUnits = Optional.fromNullable(this.jobContext.getSource().getWorkunits(jobState));
        workUnitsCreationTimer.stop();

        // *** 省略代码

        // 创建tasks
        TimingEvent workUnitsPreparationTimer =
            this.eventSubmitter.getTimingEvent(TimingEventNames.LauncherTimings.WORK_UNITS_PREPARATION);
        prepareWorkUnits(JobLauncherUtils.flattenWorkUnits(workUnits.get()), jobState);
        workUnitsPreparationTimer.stop();

        // *** 省略代码

        // 运行task
        TimingEvent jobRunTimer =           this.eventSubmitter.getTimingEvent(TimingEventNames.LauncherTimings.JOB_RUN);
        // Start the job and wait for it to finish
        runWorkUnits(workUnits.get());
        jobRunTimer.stop();

        // 如果取消了job则跳过后续的commit/publish 以及persist
        if (jobState.getState() == JobState.RunningState.CANCELLED) {
          LOG.info(String.format(&quot;Job %s has been cancelled, aborting now&quot;, jobId));
          return;
        }

        // *** 省略代码

        // 进行commit和publisher以及persist过程, 其中commit调用了JobContext的commit方法
        TimingEvent jobCommitTimer =            this.eventSubmitter.getTimingEvent(TimingEventNames.LauncherTimings.JOB_COMMIT);
        this.jobContext.finalizeJobStateBeforeCommit();
        this.jobContext.commit();
        postProcessJobState(jobState);
        jobCommitTimer.stop();

        // *** 省略代码
        // clean up
        cleanupStagingData(jobState);
        // 释放job锁
        unlockJob();

}
</code></pre>

<p>以上就是gobblin的工作流的各阶段, 从设计上看, commit/publiser 和 persist与task任务的运行彻底分开来了。task只负责数据的转换, 不管数据的落地。</p>

<h4 id="toc_2">commit/publiser 和 persist</h4>

<p>commit/publiser 和 persist是在JobContext的commit方法内实现的。</p>

<pre><code class="language-java">void commit() throws IOException {  

    // *** 省略代码
    commitDataset(datasetState, closer.register(DataPublisher.getInstance(dataPublisherClass, datasetState)));

    // *** 省略代码

    persistDatasetState(datasetUrn, datasetState);
}

/**
 * Commit the output data of a dataset.
 */
@SuppressWarnings(&quot;unchecked&quot;)
private void commitDataset(JobState.DatasetState datasetState, DataPublisher publisher) throws IOException {

  try {
    publisher.publish(datasetState.getTaskStates());
  } catch (Throwable t) {
    LOG.error(&quot;Failed to commit dataset&quot;, t);
    setTaskFailureException(datasetState.getTaskStates(), t);
  }

  // Set the dataset state to COMMITTED upon successful commit
  datasetState.setState(JobState.RunningState.COMMITTED);
}

/**
 * Persist dataset state of a given dataset identified by the dataset URN.
 */
private void persistDatasetState(String datasetUrn, JobState.DatasetState datasetState) throws IOException {
  LOG.info(&quot;Persisting dataset state for dataset &quot; + datasetUrn);
  this.datasetStateStore.persistDatasetState(datasetUrn, datasetState);
}
</code></pre>

<p>当然commit不会这么简单, Gobblin内有个publish策略,</p>

<ul>
<li>The JobCommitPolicy.COMMIT_ON_PARTIAL_SUCCESS policy 只要部分task成功.</li>
<li>The JobCommitPolicy.COMMIT_SUCCESSFUL_TASKS policy .</li>
<li>The JobCommitPolicy.COMMIT_ON_FULL_SUCCESS policy 所有task都成功.</li>
</ul>

<p>需要满足以下条件才能进行commit</p>

<pre><code class="language-java">private boolean canCommitDataset(JobState.DatasetState datasetState) {
  // Only commit a dataset if 1) COMMIT_ON_PARTIAL_SUCCESS is used, or 2)
  // COMMIT_ON_FULL_SUCCESS is used and all of the tasks of the dataset have succeeded.
  return this.jobCommitPolicy == JobCommitPolicy.COMMIT_ON_PARTIAL_SUCCESS
      || this.jobCommitPolicy == JobCommitPolicy.COMMIT_SUCCESSFUL_TASKS
      || (this.jobCommitPolicy == JobCommitPolicy.COMMIT_ON_FULL_SUCCESS
          &amp;&amp; datasetState.getState() == JobState.RunningState.SUCCESSFUL);
}
</code></pre>

<p>至此已经简要介绍了Gobblin的工作流的源码。那么下一节将重点介绍Gobblin的任务流。</p>

<h2 id="toc_3">任务流</h2>

<p>同样引用<a href="http://lamborryan.github.io/gobblin-first-exploration/">《Gobblin系列一之初探》</a>中关于任务流的图示<br/>
<img src="media/15155066323075/gobblin-5.png" alt="gobblin-5"/></p>

<p>我们先从上节的runWorkUnits(workUnits.get())method开始讲起。</p>

<pre><code class="language-java">public static List&lt;Task&gt; runWorkUnits(String jobId, List&lt;WorkUnit&gt; workUnits, TaskStateTracker stateTracker,
    TaskExecutor taskExecutor, CountDownLatch countDownLatch) {

  List&lt;Task&gt; tasks = Lists.newArrayList();
  for (WorkUnit workUnit : workUnits) {
    String taskId = workUnit.getProp(ConfigurationKeys.TASK_ID_KEY);
    WorkUnitState workUnitState = new WorkUnitState(workUnit);
    workUnitState.setId(taskId);
    workUnitState.setProp(ConfigurationKeys.JOB_ID_KEY, jobId);
    workUnitState.setProp(ConfigurationKeys.TASK_ID_KEY, taskId);

    // Create a new task from the work unit and submit the task to run
    Task task = new Task(new TaskContext(workUnitState), stateTracker, taskExecutor, Optional.of(countDownLatch));
    stateTracker.registerNewTask(task);
    tasks.add(task);
    taskExecutor.execute(task);
  }

  new EventSubmitter.Builder(JobMetrics.get(jobId).getMetricContext(), &quot;gobblin.runtime&quot;).build()
      .submit(EventNames.TASKS_SUBMITTED, &quot;tasksCount&quot;, Integer.toString(workUnits.size()));

  return tasks;
}
</code></pre>

<p>Gobblin为每一个workunit启动了一个task，由此可见任务流运行在Task类中, 且主要逻辑在Task的run方法内。而跟任务流逻辑有关的又分为两个类即Task类和Fork类。Task相当于主线程, Fork相当于分支线程.</p>

<h4 id="toc_4">Task逻辑</h4>

<pre><code class="language-java">public void run() {
    // *** 省略代码

    // 根据source的getExtractor获取每个workunit对应的extractor
    extractor =
        closer.register(new InstrumentedExtractorDecorator(this.taskState, this.taskContext.getExtractor()));

    // 根据配置, 获取1个或者多个级连起来的converter
    converter = closer.register(new MultiConverter(this.taskContext.getConverters()));

    // 根据配置获取其他分支fork, 如果只有一个分支就为IdentityForkOperator
    // Get the fork operator. By default IdentityForkOperator is used with a single branch.
     ForkOperator forkOperator = closer.register(this.taskContext.getForkOperator());

    // *** 省略代码
    // 以一个record为最小单位处理数据, 首先经过MultiConverter的convertRecord, 然后进入processRecord过程
    while ((record = extractor.readRecord(null)) != null) {
        recordsPulled++;
        for (Object convertedRecord : converter.convertRecord(schema, record, this.taskState)) {
            processRecord(convertedRecord, forkOperator, rowChecker, rowResults, branches);
        }
    ｝

    // fork会等待main branch的任务完成
    for (Optional&lt;Fork&gt; fork : this.forks) {
      if (fork.isPresent()) {
        // Tell the fork that the main branch is completed and no new incoming data records should be expected
        fork.get().markParentTaskDone();
      }
    }

    // 开始每一个fork 并行进行处理
    for (Optional&lt;Fork&gt; fork : this.forks) {
      if (fork.isPresent()) {
        try {
          this.forkCompletionService.take();
        } catch (InterruptedException ie) {
          Thread.currentThread().interrupt();
        }
      }
    }

    // 这里进行task level checker, 并进行commit
    // Check if all forks succeeded
      boolean allForksSucceeded = true;
      for (Optional&lt;Fork&gt; fork : this.forks) {
        if (fork.isPresent()) {
          if (fork.get().isSucceeded()) {
            if (!fork.get().commit()) {
              allForksSucceeded = false;
            }
          } else {
            allForksSucceeded = false;
          }
        }
      }

    // pulisher data。
    if (shouldPublishDataInTask()) {
      // If data should be published by the task, publish the data and set the task state to COMMITTED.
      // Task data can only be published after all forks have been closed by closer.close().
      publishTaskData();
      this.taskState.setWorkingState(WorkUnitState.WorkingState.COMMITTED);
    }
}

</code></pre>

<blockquote>
<p>咦, 怎么在task里面也要进行publish？这是因为pulisher分为task-level和job－level。 上一节介绍的是job－leverl, 而本节讲到的是task-level. 如果设置了job-level publish那么这里就不会publish了。 两者的主要区别在于一个粗细精度的问题。</p>
</blockquote>

<p>上面介绍任务流并没有完, 还没讲processRecord这个方法呢</p>

<pre><code class="language-java">
private void processRecord(Object convertedRecord, ForkOperator forkOperator, RowLevelPolicyChecker rowChecker,
    RowLevelPolicyCheckResults rowResults, int branches) throws Exception {

    // 对每一条record进行row-level row checker
    // Skip the record if quality checking fails
    if (!rowChecker.executePolicies(convertedRecord, rowResults)) {
        return;
    }

    // *** 省略代码

    // Put the record into the record queue of each fork. A put may timeout and return a false, in which
    // case the put needs to be retried in the next iteration along with other failed puts. This goes on
    // until all puts succeed, at which point the task moves to the next record.
    while (!allPutsSucceeded) {
      allPutsSucceeded = true;
      for (int i = 0; i &lt; branches; i++) {
        if (succeededPuts[i]) {
          continue;
        }
        if (this.forks.get(i).isPresent() &amp;&amp; forkedRecords.get(i)) {
          boolean succeeded = this.forks.get(i).get()
              .putRecord(convertedRecord instanceof Copyable ? ((Copyable) convertedRecord).copy() : convertedRecord);
          succeededPuts[i] = succeeded;
          if (!succeeded) {
            allPutsSucceeded = false;
          }
        } else {
          succeededPuts[i] = true;
        }
      }
}

</code></pre>

<p>从上面代码可以看出 processRecord主要处理以下几个逻辑。</p>

<ul>
<li>对record进行task-level row checker, 失败就返回</li>
<li>对每一条数据进行copy,然后将record放入每一个fork的queue里面。由此可见, 要实现fork必须要实现copyable接口，每一个fork保存完整的一份数据在其queue里面。所以当数据量大时且fork多时很容易出现oom</li>
<li>fork等待main branch运行且处理完所有数据后才运行. fork的运行是并行的。</li>
<li>在运行完fork后, task会对每一个fork分支进行task level checker, 如果通过则进行commit。</li>
</ul>

<h4 id="toc_5">Fork 逻辑</h4>

<p>在task中this.forkCompletionService.take()其实就是启动了fork线程的run方法。 Fork 的主要处理逻辑在Fork.processRecords方法内。</p>

<pre><code class="language-java">
/**
  * Get new records off the record queue and process them.
  */
 private void processRecords() throws IOException, DataConversionException {
   while (true) {
     try {
       // 从Fork的queue中一条一条的获取record
       Object record = this.recordQueue.get();
       if (record == null) {
         // The parent task has already done pulling records so no new record means this fork is done
         if (this.parentTaskDone) {
           return;
         }
       } else {
         // 如果没有创建writer则创建，一般情况下创建的是PartitionedDataWriter, 关于PartitionedDataWriter将在下一篇文章中介绍。
         buildWriterIfNotPresent();

         // Convert the record, check its data quality, and finally write it out if quality checking passes.
         // 对一个或者多个covert进行级连处理
         for (Object convertedRecord : this.converter.convertRecord(this.convertedSchema, record, this.taskState)) {
           // 进行row-level的checker, 如果没有错误则进行writer
           if (this.rowLevelPolicyChecker.executePolicies(convertedRecord, this.rowLevelPolicyCheckingResult)) {
             this.writer.get().write(convertedRecord);
           }
         }
       }
     } catch (InterruptedException ie) {
       this.logger.warn(&quot;Interrupted while trying to get a record off the queue&quot;, ie);
       Throwables.propagate(ie);
     }
   }

</code></pre>

<p>Fork processRecords 的处理逻辑跟Task的 processRecords 类似, 只是多了writer, 关于writer的部分将在下一篇文章中介绍。</p>

<p>至此，关于fork的处理逻辑也结束了。这里需要注意一点的是，由于coverter和rowLevelPolicyChecker都是支持多个级连的，所以在实现过程中分别采用了mutilCoverter这个chain的方法和for循环的方法.</p>

<p>mutilCoverter</p>

<pre><code class="language-java">@Override
public Iterable&lt;Object&gt; convertRecord(Object outputSchema, final Object inputRecord, final WorkUnitState workUnit)
    throws DataConversionException {

  if (this.convertedSchemaMap.size() != this.converters.size()) {
    throw new RuntimeException(&quot;convertRecord should be called only after convertSchema is called&quot;);
  }

  return new Iterable&lt;Object&gt;() {
    @Override
    public Iterator&lt;Object&gt; iterator() {
      try {
        return new MultiConverterIterator(inputRecord, workUnit);
      } catch (DataConversionException dce) {
        throw new RuntimeException(dce);
      }
    }
  };
}

public MultiConverterIterator(Object inputRecord, WorkUnitState workUnitState) throws DataConversionException {
  this.workUnitState = workUnitState;
  this.chainedConverterIterator =
      new ChainedConverterIterator(new SingleRecordIterable&lt;Object&gt;(inputRecord).iterator(), converters.isEmpty()
          ? new IdentityConverter() : converters.get(0));

  for (int i = 1; i &lt; converters.size(); i++) {
    this.chainedConverterIterator =
          new ChainedConverterIterator(this.chainedConverterIterator, converters.get(i));
  }
}
</code></pre>

<p>rowLevelPolicyChecker</p>

<pre><code class="language-java">public boolean executePolicies(Object record, RowLevelPolicyCheckResults results) throws IOException {
  for (RowLevelPolicy p : this.list) {
    RowLevelPolicy.Result result = p.executePolicy(record);
    results.put(p, result);

    if (result.equals(RowLevelPolicy.Result.FAILED)) {
      if (p.getType().equals(RowLevelPolicy.Type.FAIL)) {
        throw new RuntimeException(&quot;RowLevelPolicy &quot; + p + &quot; failed on record &quot; + record);
      } else if (p.getType().equals(RowLevelPolicy.Type.ERR_FILE)) {
        if (!errFileOpen) {
          this.writer.open(getErrFilePath(p));
          this.writer.write(record);
        } else {
          this.writer.write(record);
        }
        errFileOpen = true;
      }
      return false;
    }
  }
  return true;
}

</code></pre>

<h2 id="toc_6">总结</h2>

<p>本文简单的通过源码来分析gobblin-runtime是如何完成工作流和任务流的. 主要涉及到3个类, AbstractJobLauncher, Task， Fork. 其中关于更细的Source, Extractor，Coverter, Writer, DataPublisher 将在后面文章中分别介绍。<br/>
最后用一副我画的图来总结下全文吧.<br/>
<img src="media/15155066323075/gobblin-6.png" alt="gobblin-6"/></p>

<p>本文完</p>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-state">http://lamborryan.github.io/gobblin-state</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gobblin系列(3)之Azkaban Schedule]]></title>
    <link href="www.lamborryan.com/15155065803565.html"/>
    <updated>2018-01-09T22:03:00+08:00</updated>
    <id>www.lamborryan.com/15155065803565.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">前言</a>
</li>
<li>
<a href="#toc_1">配置过程</a>
<ul>
<li>
<a href="#toc_2">注意事项</a>
</li>
<li>
<a href="#toc_3">安装Azkaban jobtype plugin</a>
</li>
<li>
<a href="#toc_4">Gobblin Job</a>
<ul>
<li>
<a href="#toc_5">创建Gobblin的azkaban Job</a>
</li>
<li>
<a href="#toc_6">创建gobblin job</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_7">总结</a>
</li>
</ul>


<h2 id="toc_0">前言</h2>

<p>Gobblin支持三种Schedule即Quartz, Azkaban, Oozie, 默认是采用Quartz. 由于项目的工作流schedule已经采用Azkaban, 所以要将Gobblin Task配置到Azkaban. 但是没相到以为分分钟就能搞定的结果花了我整整一天的时间, 主要问题还是因为Gobblin的资料的匮乏, 在这实现过程中我查阅了Gobblin，Azkaban 和Azkaban-jobtype plugin的源码, 可见繁琐程度. 本文将描述怎么配置Gobblin-Azkaban，并结合主要的代码流程。之所以采用azkaban, 主要因为azkaban使用简单，能有效的进行工作流依赖管理。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">配置过程</h2>

<h3 id="toc_2">注意事项</h3>

<p>首先需要注意以下两点:</p>

<ul>
<li>使用bin/gobblin-standalone.sh启动gobblin-standalone模式采用的是Quartz模式. job.schedule就是按照Quartz的规则来实现定时任务。所以要实现Azkaban Schedule第一步就需要关闭gobblin-standalone进程, 删掉job.schedule配置。</li>
<li>实现Azkaban Schedule的另一个前提条件是配置Azkaban的jobtype plugin。这是因为Gobblin-Azkaban需要通过hadoopJava或者java jobtype来实现的.</li>
</ul>

<p>在Gobblin的文档上关于配置Azkaban Schedule只有以下这段话:</p>

<blockquote>
<p>Gobblin can be launched via Azkaban, and open-source Workflow Manager for scheduling and launching Hadoop jobs. Gobblin&#39;s AzkabanJobLauncher can be used to launch a Gobblin job through Azkaban.</p>

<p>One has to follow the typical setup to create a zip file that can be uploaded to Azkaban (it should include all dependent jars, which can be found in gobblin-dist.tar.gz). The .job file for the Azkaban Job should contain all configuration properties that would be put in a .pull file (for example, the Wikipedia Example .pull file). All Gobblin system dependent properties (e.g. conf/gobblin-mapreduce.properties or conf/gobblin-standalone.properties) should also be in the zip file.</p>

<p>In the Azkaban .job file, the type parameter should be set to hadoopJava (see here for more information about the hadoopJava Job Type). The job.class parameter should be set to gobblin.azkaban.AzkabanJobLauncher.</p>
</blockquote>

<h3 id="toc_3">安装Azkaban jobtype plugin</h3>

<p>1.下载<a href="https://s3.amazonaws.com/azkaban2/azkaban-plugins/2.5.0/azkaban-jobtype-2.5.0.tar.gz">azkaban-jobtype-2.5.0.tar.gz</a> ,由于在amazonaws上所以下载速度很慢。</p>

<p>2.将azkaban-jobtype-2.5.0.tar.gz 解压到${AZKABAN_HOME}/plugins目录下, 并建立软连接</p>

<pre><code class="language-bash">ln -s azkaban-jobtype-2.5.0 jobtype
</code></pre>

<p>3.修改${AZKABAN_HOME}/conf/azkaban.properties, 增加配置</p>

<pre><code class="language-bash">azkaban.jobtype.plugin.dir=plugins/jobtype
</code></pre>

<p>4.配置jobtype插件, 修改${AZKABAN_HOME}/plugins/jobtype/common.properties</p>

<pre><code class="language-bash">hadoop.home=/opt/hadoop
#hive.home=/opt/hive
jobtype.global.classpath=${hadoop.home}/etc/hadoop/*,${hadoop.home}/lib/native/*,${hadoop.home}/share/common/*,${hadoop.home}/share/hdfs/*,${hadoop.home}/    share/yarn/*
</code></pre>

<p>5.重启Azkaban</p>

<pre><code class="language-bash">bin/azkaban-solo-start.sh
</code></pre>

<p>需要注意的是这里的配置使用的是相对路径, 所以需要在${AZKABAN_HOME}目录下运行bin/azkaban-solo-start.sh命令。</p>

<h3 id="toc_4">Gobblin Job</h3>

<h4 id="toc_5">创建Gobblin的azkaban Job</h4>

<p>新建job文件gobblin_test.job</p>

<pre><code class="language-bash">type=java
job.class=gobblin.azkaban.AzkabanJobLauncher
classpath=/data/bmw/services/gobblin/gobblin/lib/*
ENV.JOB_PROP_FILE=hdfs_standalone_txt_test.pull
method.run=run
method.cancel=cancel
</code></pre>

<blockquote>
<p>虽然官方文档中说JobType要设置为hadoopJava, 但是在实际应用中如果设置为hadoopJava, 那么会存在gobblin job会一直运行不会结束的bug, 当我把JobType设置为java后运行正常. 所以本文后续全部使用java jobtype。 bug类似于<a href="https://groups.google.com/forum/#!searchin/gobblin-users/azkaban/gobblin-users/wxegYW_FGbI/1dA-KgpQCQAJ">这里</a></p>
</blockquote>

<p>从上面的例子可以看出几个要素。</p>

<p>1.配置gobblin的azkaban Job需要设置Job Type为java，所以Azkaban会使用jobtype plugin的JavaJobRunnerMain来启动Gobblin Job。</p>

<pre><code class="language-java">public JavaJobRunnerMain() throws Exception {
    // 代码省略
    * * *

    // 根据job.class配置项实例化gobblin.azkaban.AzkabanJobLauncher类
    _javaObject = getObject(_jobName, className, prop, _logger);
    if (_javaObject == null) {
        _logger.info(&quot;Could not create java object to run job: &quot; + className);
        throw new Exception(&quot;Could not create running object&quot;);
    }

    // 根据method.cancel配置项映射到gobblin.azkaban.AzkabanJobLauncher的method, 默认method为cancel
    _cancelMethod = prop.getProperty(CANCEL_METHOD_PARAM, DEFAULT_CANCEL_METHOD);

    // 根据method.run配置项映射到gobblin.azkaban.AzkabanJobLauncher的method, 默认method为run
    final String runMethod = prop.getProperty(RUN_METHOD_PARAM, DEFAULT_RUN_METHOD);
    _logger.info(&quot;Invoking method &quot; + runMethod);

    if (shouldProxy(prop)) {
        _logger.info(&quot;Proxying enabled.&quot;);
        runMethodAsUser(prop, _javaObject, runMethod, proxyUser);
    } else {
        _logger.info(&quot;Proxy check failed, not proxying run.&quot;);
        // 运行gobblin.azkaban.AzkabanJobLauncher的run method.
        runMethod(_javaObject, runMethod);
    }
    // 代码省略
    * * *
}

private void runMethod(Object obj, String runMethod) throws IllegalAccessException, InvocationTargetException,
        NoSuchMethodException {
    obj.getClass().getMethod(runMethod, new Class&lt;?&gt;[] {}).invoke(obj);
}
</code></pre>

<p>从代码片段上可以看出Azakan根据Java配置来决定调用JavaJobRunnerMain, 而JavaJobRunnerMain实例化了gobblin.azkaban.AzkabanJobLauncher 并调用其run 方法来launcher gobblin job, 使用canel方法来停止gobblin job。</p>

<p>AzkabanJobLauncher 的代码片段如下, 其中关于AzkabanJobLauncher的内容超出本文的界限, 在后续文章中详细介绍。</p>

<pre><code class="language-java">    @Override
    public void run()
        throws Exception {
      try {
        if (isCurrentTimeInRange()) {
          this.jobLauncher.launchJob(this.jobListener);
        }
      } finally {
        this.closer.close();
      }
    }

    @Override
    public void cancel()
        throws Exception {
      try {
        this.jobLauncher.cancelJob(this.jobListener);
      } finally {
        this.closer.close();
      }
    }
</code></pre>

<p>2.classpath配置项为需要调用的job.class的路径, 在本文也就是${GOBBLIN_HOME}/lib</p>

<p>3.ENV.JOB_PROP_FILE=hdfs_standalone_txt_test.pull</p>

<p>构造AzkabanJobLauncher实例的时候需要传入gobblin job的运行参数, 这就需要通过环境变量来传递配置文件路径。</p>

<p>下面依然是JavaJobRunnerMain是代码断</p>

<pre><code class="language-java">public JavaJobRunnerMain() throws Exception {
    // 代码省略
    * * *

    _jobName = System.getenv(ProcessJob.JOB_NAME_ENV);
    //获取ENV.JOB_PROP_FILE的路径
    String propsFile = System.getenv(ProcessJob.JOB_PROP_ENV);

    // 加载配置文件内容
    Properties prop = new Properties();
    prop.load(new BufferedReader(new FileReader(propsFile)));

    // 通过反射机制实例化AzkabanJobLauncher
    _javaObject = getObject(_jobName, className, prop, _logger);

    // 代码省略
    * * *
}
</code></pre>

<p>至此已经完成了azkaban job的配置</p>

<h4 id="toc_6">创建gobblin job</h4>

<p>配置gobblin job跟standalone是相似的, 不同之处在于</p>

<ol>
<li>上文介绍的删除job.shedule</li>
<li>增加launcher.type=LOCAL 和 job.class=gobblin.azkaban.AzkabanJobLauncher</li>
<li>需要将gobblin-standalone.properties跟.pull配置里不同的配置项补充到.pull配置中</li>
</ol>

<h2 id="toc_7">总结</h2>

<p>本文介绍了gobblin如何结合azkaban配置工作流调度, 并简要介绍了调度源码。由于gobblin的资料实在太少, 所以往往只能查阅源码，不过这也是一件有趣的事情。</p>

<p>本文完</p>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-state">http://lamborryan.github.io/gobblin-state</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gobblin系列(2)之History Store 和 Admin Server]]></title>
    <link href="www.lamborryan.com/15155064360093.html"/>
    <updated>2018-01-09T22:00:36+08:00</updated>
    <id>www.lamborryan.com/15155064360093.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">简介</a>
</li>
<li>
<a href="#toc_1">History Store</a>
</li>
<li>
<a href="#toc_2">Admin Server</a>
<ul>
<li>
<a href="#toc_3">Web Ui</a>
</li>
<li>
<a href="#toc_4">client</a>
</li>
</ul>
</li>
<li>
<a href="#toc_5">总结</a>
<ul>
<li>
<a href="#toc_6">展示所有的job(相同的job只显示一个)</a>
</li>
<li>
<a href="#toc_7">展示job的所有历史记录</a>
</li>
<li>
<a href="#toc_8">展示某个job实例的detail信息, 可查看task, properties[View Job Properties]和metrix[View Metrics]</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">简介</h2>

<p>在阅读Gobblin的时候突然发现Gobblin其实是自带一个Admin Server以及History Store来存放历史的job运行数据, 所以也就研究了下这块内容。 这也反应了Gobblin的一个缺点即文档和资料的缺乏, 不过还好有源码。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">History Store</h2>

<p>History Store的内容在<a href="https://github.com/linkedin/gobblin/wiki/Job%20Execution%20History%20Store">《Gobblin文档》</a>里有介绍, 代码对应gobblin-metastore package.</p>

<p>History Store 数据是存放在mysql上，所以需要在配置中加入以下内容:</p>

<ul>
<li>job.history.store.enabled=true</li>
<li>job.history.store.url=jdbc:mysql://data1/gobblin?createDatabaseIfNotExist=true</li>
<li>job.history.store.jdbc.driver=com.mysql.jdbc.Driver</li>
<li>job.history.store.user=gobblin</li>
<li>job.history.store.password=gobblin</li>
</ul>

<p>但是配置完以后并不能立马就实现, 这是因为gobblin不会自动生成元数据表, 这一点有点挫.</p>

<p>所以需要手动建立gobblin数据库, 然后再在gobblin数据库内建相应的表。关于表的字段请自己看文档。</p>

<ul>
<li>gobblin_job_executions</li>
<li>gobblin_task_executions</li>
<li>gobblin_job_metrics</li>
<li>gobblin_task_metrics</li>
<li>gobblin_job_properties</li>
<li>gobblin_task_properties</li>
</ul>

<p>好在, gobblin-metastore package自带了建表的sql: gobblin_job_history_store.sql。</p>

<p>这样每次执行完job, job的status和metrix就会保存在gobblin数据库里, 这位Admin Server来监控数据提供了先觉条件。</p>

<h2 id="toc_2">Admin Server</h2>

<h3 id="toc_3">Web Ui</h3>

<p>有了History Admin, 那么我们可以通过Admin Server来监控历史job的运行状况。默认情况下是不启动Admin Server, 我们来看下源码。跟Admin Server有关的package有以下几个</p>

<ul>
<li>gobblin-admin: admin 管理界面, 包括server和client. Admin Server是基于jetty运行的, 通过与rest server来获取具体数据;</li>
<li>gobblin-rest-server: rest server是一个运行Rest.li的服务, 主要处理请求以及history store查询;</li>
<li>gobblin-rest-api: Rest api, 暂不介绍。</li>
<li>gobblin-rest-client: Rest.li 客户端, 与Rest Server交互获取job执行信息。</li>
</ul>

<p>由此可见要进行admin 监控, 至少需要启两个服务:admin Server, rest server 并配置开启history store.</p>

<pre><code class="language-java">public SchedulerDaemon(Properties defaultProperties, Properties customProperties)
    throws Exception {
  Properties properties = new Properties();
  properties.putAll(defaultProperties);
  properties.putAll(customProperties);

  List&lt;Service&gt; services = Lists.&lt;Service&gt;newArrayList(new JobScheduler(properties));
  boolean jobExecInfoServerEnabled = Boolean
      .valueOf(properties.getProperty(ConfigurationKeys.JOB_EXECINFO_SERVER_ENABLED_KEY, Boolean.FALSE.toString()));
  if (jobExecInfoServerEnabled) {
    JobExecutionInfoServer executionInfoServer = new JobExecutionInfoServer(properties);
    services.add(executionInfoServer);
    if (shouldRunAdminServer(properties)) {
      services.add(new AdminWebServer(properties, executionInfoServer.getServerUri()));
    }
  }
  this.serviceManager = new ServiceManager(services);
}
</code></pre>

<p>在SchedulerDaemon里面会启动2个server, JobExecutionInfoServer, AdminWebServer 分别对应rest server和 admin server, 而要启动这两个server需要有相应的配置job.execinfo.server.enabled和admin.server.enabled，默认都是关闭的.</p>

<ul>
<li>admin.server.enabled=true</li>
<li>admin.server.port=17878</li>
<li>job.execinfo.server.enabled=true</li>
<li>rest.server.host=data4</li>
<li>rest.server.host=18080</li>
</ul>

<p>Gobblin的Rest Server是基于linkin的Rest.li开发的, 所以url还是有点奇怪的:</p>

<ul>
<li>http://<a href="hostname:port">hostname:port</a>/jobExecutions/idType=JOB_NAME&amp;id.string=TestJobName&amp;limit=10</li>
</ul>

<p>最后说明下, admin server的js库和css库有部分是被墙的, 所以web生成速度很慢, 需要把这些js库下载下来添加到本地。</p>

<h3 id="toc_4">client</h3>

<p>同样我们可以通过gobblin-admin.sh 来查看job信息:</p>

<pre><code class="language-bash">[bmw@data4 bin]$ sh gobblin-admin.sh --logdir ./ help
gobblin-admin.sh [JAVA_OPTION] COMMAND [OPTION]
Where JAVA_OPTION can be:
  --fwdir &lt;fwd dir&gt;                              Gobblin&#39;s dist directory: if not set, taken from ${GOBBLIN_FWDIR}
  --logdir &lt;log dir&gt;                             Gobblin&#39;s log directory: if not set, taken from ${GOBBLIN_LOG_DIR}
  --jars &lt;comma-separated list of job jars&gt;      Job jar(s): if not set, ${GOBBLIN_FWDIR/lib} is examined
  --help                                         Display this help and exit
COMMAND is one of the following:
  jobs|tasks
And OPTION are any options associated with the command, as specified by the CLI.
[bmw@data4 bin]$ sh gobblin-admin.sh --logdir ./ jobs -list
Job Name                State      Last Run Started     Last Run Completed   Schedule        Last Run Records Processed  Last Run Records Failed
Dev2KafkaHDFSAVRO_test  COMMITTED  2016-03-18T17:30:00  2016-03-18T17:30:04  0 */15 * * * ?          21157.249109155135                      0.0
</code></pre>

<h2 id="toc_5">总结</h2>

<p>最后展示下效果web的效果吧:</p>

<h3 id="toc_6">展示所有的job(相同的job只显示一个)</h3>

<p><img src="media/15155064360093/gobblin-web-1.png" alt="gobblin-web-1"/></p>

<h3 id="toc_7">展示job的所有历史记录</h3>

<p><img src="media/15155064360093/gobblin-web-2.png" alt="gobblin-web-2"/></p>

<h3 id="toc_8">展示某个job实例的detail信息, 可查看task, properties[View Job Properties]和metrix[View Metrics]</h3>

<p><img src="media/15155064360093/gobblin-web-3.png" alt="gobblin-web-3"/></p>

<p>本文主要介绍了如何配置实现gobblin的web监控以及history store。总体来说, 这个监控做的还是不错的。<br/>
下一篇将简要介绍gobblin-runtime。</p>

<p>本文完</p>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-state">http://lamborryan.github.io/gobblin-state</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gobblin系列(1)一之初探]]></title>
    <link href="www.lamborryan.com/15155061559657.html"/>
    <updated>2018-01-09T21:55:55+08:00</updated>
    <id>www.lamborryan.com/15155061559657.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">简介</a>
</li>
<li>
<a href="#toc_1">框架</a>
</li>
<li>
<a href="#toc_2">工作流</a>
</li>
<li>
<a href="#toc_3">任务组成</a>
<ul>
<li>
<a href="#toc_4">Source and Extractor</a>
</li>
<li>
<a href="#toc_5">Converter</a>
</li>
<li>
<a href="#toc_6">Quality Checker</a>
</li>
<li>
<a href="#toc_7">Fork Operator</a>
</li>
<li>
<a href="#toc_8">Data Writer</a>
</li>
<li>
<a href="#toc_9">Data Publisher</a>
</li>
</ul>
</li>
<li>
<a href="#toc_10">任务流</a>
</li>
<li>
<a href="#toc_11">状态管理</a>
</li>
<li>
<a href="#toc_12">失败处理</a>
</li>
<li>
<a href="#toc_13">工作调度</a>
</li>
<li>
<a href="#toc_14">总结</a>
</li>
</ul>


<hr/>

<p>由于需要从kafka批量把日志dump到hdfs上，所以我们使用了linkin的Gobblin工具。Gobblin目前还处于开发阶段，资料比较少，文档介绍的也不是很详细，要使用他只能去阅读源码。因此我打算通过一系列的Gobblin的文章来记录下我的学习使用心得。</p>

<p>本文主要初步介绍Gobblin的基础框架, 主要内容来自<a href="https://github.com/linkedin/gobblin/wiki/Gobblin-Architecture">《官方文档》</a><br/>
, 然后在后续文章中展开介绍。</p>

<p>本人使用的Gobblin版本是0.6.2</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">简介</h2>

<p>Gobblin是由linkin开源的Hadoop通用数据摄取框架，可以从各种数据源中提取，转换和加载海量数据。比如：数据库，rest APIs，kafka，等等。Gobblin 处理日常规划任务需要所有数据摄取ETLs，包括作业/任务规划，任务分配，错误处理，状态管理，数据质量检测，数据发布等等。</p>

<p>Gobblin 通过同样的执行框架从不同数据源摄取数据，在同一个地方管理所有不同数据源的元数据。同时结合了其他特性，比如自动伸缩，容错，数据质量保证，可扩展和处理数据模型改革等等。Gobblin 变得更容易使用，是个高效的数据摄取框架。</p>

<p>那么Gobblin与Sqoop有啥区别？</p>

<ul>
<li>Gobblin可以接入各种数据源, 而Sqoop只能对接关系型数据库。</li>
<li>Gobblin只管摄入, 也就是说Gobblin只能实现数据源摄入到hdfs上, 而不能实现hdfs导出其他数据源上。相反, Sqoop实现了关系型数据库跟hadoop之间的互导.</li>
<li>Gobblin支持一定的ETL,容错,数据监测等功能, 而Sqoop支持的有限的etl功能是在数据库上(sql)实现的。</li>
</ul>

<p>因此Gobblin并不能取代Sqoop, 两者是一种互补。</p>

<h2 id="toc_1">框架</h2>

<p><img src="media/15155061559657/gobblin-1.png" alt="gobblin-1"/></p>

<p>Gobblin一开始设计就把可扩展性考虑了进去，因此开发者只要开发相应的adapter或者使用已有的adapter就可以实现相应的功能。</p>

<ul>
<li>Gobblin由一系列负责不同功能的task和workunit组成(绿色部分)。在Gobblin中task分为Source,Extractor,Converter,QualityChecker,Writer,Publisher这几种组成(浅绿色部分),在下文的任务流模块中将更详细介绍, 对应gobblin-core package</li>
<li>Gobblin的任务运行在Gobblin Runtime内核中(橘黄色部分),它负责job/task调度, 运行失败处理, 状态管理, 资源申请, 数据质量检测等, 对应gobblin-runtime package</li>
<li>Gobblin可以有两种实现方式(红色部分), 1.单机, 2.MapReduce, 当然也支持yarn的资源管理。</li>
<li>最后蓝色部分就是元数据管理,任务监控。</li>
</ul>

<h2 id="toc_2">工作流</h2>

<p>一个Gobblin Job即是一次完整的数据摄取过程.</p>

<p><img src="media/15155061559657/gobblin-2.png" alt="gobblin-2"/></p>

<ol>
<li>job开始时候首先会设置job lock, 防止后续的job在前一个未完成的情况下启动，比如设置了Azkaban负责调度, 就会有定时启动设置.</li>
<li>Gobblin 会根据配置文件创建Source。 Source主要实现两个功能: 1. 将摄取任务分成多个workunit, 每一个workunit都对应一部分数据; 2. Source还负责为每一个workunit创建Extractor, Extractor才是真正进行数据摄取的步骤。该设计同MapReduce的inputformat，inputformat负责数据的切分以及RecordReader创建, 而RecordReader才是进行数据读取的部件。</li>
<li>Gobblin会根据source创建的workunit来创建对应的一系列task, 由此可见task就是运行时态的workunit。一般情况下 task与workunit是一对一的关系，但是也存在特殊情况MultiWorkUnit, 实现多对多的映射。</li>
<li>接下来就是运行task. 单机模式下, task运行在一个线程池内，而mapreduce模式下则运行在hadoop集群上。</li>
<li>当task运行完以后job会根据配置来决定是否publish数据，如果设置了JobCommitPolicy.COMMIT_ON_PARTIAL_SUCCESS 则只要部分task成功运行就可以publish数据，而JobCommitPolicy.COMMIT_ON_FULL_SUCCESS则需要所有task运行成功。</li>
<li>当数据publish后，job会储存job/task的status。这样下一个job启动时候就可以读取这些数据比如watermarks而知道从哪里开始运行。</li>
<li>删除执行过程中产生的中间数据。</li>
<li>最后释放掉job lock, 以便下一个job运行。</li>
</ol>

<h2 id="toc_3">任务组成</h2>

<p>在工作流小节中简要介绍job的流程, 那么本节将介绍task的组成:Source, Extractor, Converter, QualityChecker,  ForkOperator, Writer, Publisher.</p>

<p><img src="media/15155061559657/gobblin-3.png" alt="gobblin-3"/></p>

<h3 id="toc_4">Source and Extractor</h3>

<p>前文讲到Source主要负责将数据切分成多个workunits以及为每一个workunit创建Extractor, 而Extractor则负责进行数据的摄取与解析。</p>

<p>Source支持各种数据源, jdbc支持的数据库, kafka, FTP/SFTP, Rest APIs等. 目前Extractor只支持以单个record颗粒度的数据摄取以及解析, 也就是说在Extractor阶段同一时间只能处理单条record。</p>

<h3 id="toc_5">Converter</h3>

<p>Converter 负责将一个record转换成另一个record, 因此对于一个Converter它需要输入的record schema和输出的record schema作为参数。</p>

<p>Converter 还支持级连，也就是说可以多个Converter 组成一个链式处理, 每一个Converter负责某一个转换。</p>

<p><img src="media/15155061559657/gobblin-4.png" alt="gobblin-4"/></p>

<p>上图就是一个Converter Chain链式操作, 它支持1:1,1:N映射。</p>

<h3 id="toc_6">Quality Checker</h3>

<p>Quality Checker 负责对数据进行质量验证, 有两种类型:</p>

<ol>
<li>对每一条record进行验证以决定是否可以进行任务流的下个步骤, 因此也称为row-level QualityChecker;</li>
<li>对全部的任务流的最终输出进行验证以决定是否提交数据, 因此也称为task-level QualityChecker。</li>
</ol>

<p>Quality Checker 分为MANDATORY和OPTIONAL，前者为强制类型，即需要满足所有的MANDATORY Checker都验证通过才会最后提交，后者只会输出提示信息。Quality Checker 也可多个组成链式。</p>

<h3 id="toc_7">Fork Operator</h3>

<p>Fork Operator 是控制任务流分支, 比如需要对同一份数据输出到不同的目录下, 就可以通过Fork来实现。</p>

<h3 id="toc_8">Data Writer</h3>

<p>DataWriter 顾名思义就是将record写到指定的地方，如hdfs上。 Gobblin 默认提供了AvroHdfsDataWriter类将数据以avro的格式写入到hdfs上。 DataWriter 是插件形式的, 开发者可以自己定制DataWriter，通过继承DataWriter和DataWriterBuilder, 并在配置文件里进行指定。</p>

<h3 id="toc_9">Data Publisher</h3>

<p>DataPublisher 将DataWriter生成的目录移动到最后的目录。</p>

<h2 id="toc_10">任务流</h2>

<p>上一节介绍了 Gobblin的由哪些任务组成, 本节通过一个完整的例子来介绍完成的一个任务流.</p>

<p><img src="media/15155061559657/gobblin-5.png" alt="gobblin-5"/></p>

<ul>
<li>一个Gobblin由一个main branch和多个forked branch组成, forked branch需要在配置中额外添加。如果没有forked branch， 则Gobblin 会使用IdentityForkOperator来创建单个分支。 IdentityForkOperator由一个main branch和单个forked branch组成。</li>
<li>需要注意的是, 每一个forked branch的输入数据是完全一样的, 所以每个branch都是Copyable的一个实例，即数据是复制的。</li>
<li>如果在每个branch中加入了task-level QualityChecker, 那么每个branch必须等检验通过了才会提交数据。</li>
<li>最后所有branch都成功了才算job成功, 在task运行过程中会有TaskStateTracker保持task status, task metrics等数据。</li>
</ul>

<h2 id="toc_11">状态管理</h2>

<p>Gobblin可以周期的运行job, 并根据已经存在的上一个周期的数据实现增量运行, 比如根据上一个job周期存下来的数据获取新增的或者改变的数据。</p>

<p>默认情况下, Gobblin会在hdfs上为每一个job建立不同的目录，并存放序列化后的数据。</p>

<h2 id="toc_12">失败处理</h2>

<p>Gobblin支持失败的job重试多次，发送email，</p>

<h2 id="toc_13">工作调度</h2>

<p>单机模式下，Gobblin默认使用Quartz scheduler, 它可以跟 Azkaban,Oozie, Crontab这些scheduler一起部署， 甚至多个联合部署。</p>

<h2 id="toc_14">总结</h2>

<p>本文主要简单介绍了Gobblin的基本概念以及框架, 通过本文可以整体上了解Gobblin是怎么工作的，有什么明显的特点。那么接下来的文章将详细展开介绍每一部分。</p>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-state">http://lamborryan.github.io/gobblin-state</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JavaCC的使用总结]]></title>
    <link href="www.lamborryan.com/15154238312203.html"/>
    <updated>2018-01-08T23:03:51+08:00</updated>
    <id>www.lamborryan.com/15154238312203.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">1.安装</a>
</li>
<li>
<a href="#toc_1">2.文件格式</a>
<ul>
<li>
<ul>
<li>
<a href="#toc_2">2.1Options部分</a>
</li>
<li>
<a href="#toc_3">2.2分析器类的声明</a>
</li>
<li>
<a href="#toc_4">2.3词法规则定义</a>
<ul>
<li>
<a href="#toc_5">1.SKIP用来说明被忽略的串, 比如碰到以下字符就跳过。</a>
</li>
<li>
<a href="#toc_6">2.TOKEN，用来说明在词法层次上识别的token，比如解析到字母就归为ID这个Token，解析到字母就归属于NUM这个TOKEN。</a>
</li>
<li>
<a href="#toc_7">3.语法规则</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_8">3.Lookahead</a>
<ul>
<li>
<a href="#toc_9">3.1 什么是Lookahead</a>
</li>
<li>
<a href="#toc_10">3.2 语法解析器的选择顺序</a>
</li>
<li>
<a href="#toc_11">3.3 怎么使用lookahed</a>
<ul>
<li>
<ul>
<li>
<a href="#toc_12">Lookahead的一般模式</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_13">4.总结</a>
</li>
<li>
<a href="#toc_14">5. 参考文献</a>
<ul>
<li>
<ul>
<li>
<a href="#toc_15">本文完。</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<hr/>

<p>最近项目SQL解析模块用到Apache Calcite了，由于需要自己定义一些语法，因此花了一段时间研究了其中的JavaCC，本文全当是笔记免得以后忘记。</p>

<span id="more"></span><!-- more -->

<p>Sql解析的第一步往往是将一串SQL字符串进行词法和语法解析。</p>

<p>所谓词法分析，就是将一行行的字符串按照实现定好的格式分割成一个个单词字符Token,比如<code>sql SELECT 1+1 FROM tb WHERE;</code>经过词法分析后就变成了单词<code>SELECT, 1, +, 1, FROM, tb, WHERE</code>。</p>

<p>而语法分析内，就是分析词法分析后的这些Token，是否符合事先定好的语法的一个，否则就会解析报错。</p>

<p>再这之后就是生成抽象语法树。JavaCC是一个不错的词法和语法解析器，它完全使用Java实现的。我们可以基于JavaCC来构建抽象语法树，比如Calcite。</p>

<p>本文主要简单介绍下使用JavaCC如何来实现词法和语法的分析。</p>

<h2 id="toc_0">1.安装</h2>

<p>安装不是本文的重点，只是说明JavaCC的语法是写在.jj文件上，而目前只有Eclipse支持JavaCC插件，Intelij Idea暂不支持。要知道开发.jj文件，是件很痛苦的事情，没有这个插件怎么受得了。<br/>
<a href="https://sourceforge.net/projects/eclipse-javacc/files/">JavaCC Eclipse插件</a></p>

<h2 id="toc_1">2.文件格式</h2>

<p>一个JJ文件主要有以下几部分组成：</p>

<h4 id="toc_2">2.1Options部分</h4>

<p>这个部分对产生的语法分析器的特性进行说明，例如向前看的token的个数（用来解除冲突）。这一部分是可以省略的，因为每一个选项都有默认值，当我们没有对某个选项进行说明时，它就采用默认值。也可以把这些选项作为javacc命令的参数来启动javacc，可以达到同样的效果。</p>

<pre><code class="language-java">options  
{  
  JDK_VERSION = &quot;1.8&quot;;   # Java版本
  STATIC = false;   # 是否以静态方法的方式提供
} 
</code></pre>

<p>更多的配置见<a href="https://javacc.org/javaccgrm">这里</a></p>

<h4 id="toc_3">2.2分析器类的声明</h4>

<p>这个部分指定了分析器类的名字，以及其他类中成员的声明。这个部分是必须有的, 他就是正常的Java代码。这个部分的声明如下：</p>

<pre><code class="language-java">PARSER_BEGIN(classname)
Class classname {
       ……
}
PARSER_END(classname)
</code></pre>

<h4 id="toc_4">2.3词法规则定义</h4>

<p>这里面有四类：SKIP、TOKEN、SPECIAL_TOKEN、MORE。</p>

<h5 id="toc_5">1.SKIP用来说明被忽略的串, 比如碰到以下字符就跳过。</h5>

<pre><code class="language-java">SKIP {
       “ “
|
       “\n”
|
       “\r”
}
</code></pre>

<h5 id="toc_6">2.TOKEN，用来说明在词法层次上识别的token，比如解析到字母就归为ID这个Token，解析到字母就归属于NUM这个TOKEN。</h5>

<pre><code class="language-java">TOKEN {
       &lt;ID: (“a”-“z”|”A”-“Z”)+&gt;
|
       &lt;NUM: (“0”-“9”)+&gt;
}
</code></pre>

<p>在词法声明部分，以#开头的token只是在词法分析时使用，不能作为语法分析的输入，也就是说，它相对词法分析是局部的。</p>

<h5 id="toc_7">3.语法规则</h5>

<p>语义规则中支持Java代码，生成的代码会直接插入分析器类声明的结束括号之前。开头是一个声明，包括返回值类型、规则名和一个冒号。对于这样一条语法规则，JavaCC就会在语法分析器类中生成一个同名的方法。紧接着的一对花括号中写一些变量声明。下一对花括号中写该规则的具体内容。<br/>
一个语法单元中有多个规则时，用|分开。每个规则都有一系列词法或语法单元组成，每个词法或者语法单元之后跟着一对花括号，里面写处理的代码。如下所示</p>

<pre><code class="language-java">Return_type function_name()

{     
    # Java代码模块
    # 变量声明和一些初始化的动作
}
{

&lt;!--       上下文无关文法的右部分，
       其中每个组成部分的形式如下：
       语法部分 {动作部分}
       两个部分都可以省略。语法部分可以是一个字符串（简单的
       token常常可以这样处理），TOKEN中声明的token，或一个
       对某个非终结符对应的函数的调用。--&gt;
}
</code></pre>

<p>我们拿Calcite的一段来进行看看如何定义语法。<br/>
以下定义了两个语法规则，GroupBy的语法规则，以及GroupBy的元素的语法规则。</p>

<pre><code class="language-java">/**
 * Parses the optional GROUP BY clause for SELECT.
 */
SqlNodeList GroupByOpt() :
{   
    # 定义JAVA的变量并初始化
    List&lt;SqlNode&gt; list = Lists.newArrayList();
    final Span s;
}
{
    &lt;GROUP&gt; # 语法解析要求先有GRPUP TOKEN 
    
    { s = span(); } # JAVA代码，计算Group Token在字符串的位置
    
    &lt;BY&gt; # 接着必须跟上BY TOKEN
    
    list = GroupingElementList()  # BY后面是一串的Group 元素，调用GroupingElementList的语法故障函数
    
    # 最后生成JAVA 代码，生成GroupBy的Statement，也就是AST的一个节点。
    {
        return new SqlNodeList(list, s.addAll(list).pos());
    }
    
| # 或者的意思，要么匹配上Group Token进入上面那个分支，要么没有匹配上没有Group 语句。
    
    {
        return null;
    }
}

List&lt;SqlNode&gt; GroupingElementList() :
{
    List&lt;SqlNode&gt; list = Lists.newArrayList();
    SqlNode e;
}
{
    e = GroupingElement() { list.add(e); }
    (
        &lt;COMMA&gt;
        e = GroupingElement() { list.add(e); }
    )*
    { return list; }
}
</code></pre>

<p>其中用到一些标记跟正则的一样：</p>

<ul>
<li>[]：其中的内容是可选的。</li>
<li>+：前面的内容出现一次或多次。</li>
<li>-：前后构成的闭区间。</li>
<li>*: 前面的内容出现0次或多次。</li>
<li>?：前面的内容出现0次或一次。</li>
<li>~：后面的内容的补。</li>
<li>：前面或后面。</li>
<li>()：改变运算的优先级，把其中的内容作为一个整体。</li>
</ul>

<p>语义解析的规则比较灵活，完全可以基于这个代码构建AST。</p>

<h2 id="toc_8">3.Lookahead</h2>

<p>javacc有一些问题，即它采用的是自顶向下的分析方法，而且没有回溯功能，因此如何解决冲突的问题，是程序员的责任。如果词法规则有二义性，JavaCC会给出警告，一定不要忽略这些警告。此外，JavaCC只对开头存在二义性的词法给出警告（一个字符可以作为两个词法规则的第一个字符），有些词法上的冲突是需要我们自己去注意的。</p>

<p>不过Java使用LookAhead的方法帮助我们来解决冲突。</p>

<h3 id="toc_9">3.1 什么是Lookahead</h3>

<p>假设以下这个语义规则</p>

<pre><code class="language-java">void Input() :
{}
{
&quot;a&quot; BC() &quot;c&quot;
}

void BC() :
{}
{
&quot;b&quot; [ &quot;c&quot; ]
}
</code></pre>

<p>假设有两个字符串 <code>abc</code>, 我们来模拟下语法解析过程。</p>

<ul>
<li>1. 首先输入a字符，发现只有1个选择，即a是命中的。</li>
<li>2. 第二步是b字符，同样只有1个选择，即进入到BC规则中，命中B。</li>
<li>3. 第三步是c字符，我们有两个选择，命中BC规则的c还是跳出BC规则从而命中外层的c呢，那我们首先选择命中BC规则的c。</li>
<li>4. 第四步BC规则已经结束，那么跳出BC，进入外层，外层需要匹配c，但是我们已经没有字符了，所以刚才的步骤是错的。</li>
<li>5. 第五步就是回溯到第三步，然后我们选择忽略BC规则的c，然后跳出bc，命中外层的c。因此解析完成。</li>
</ul>

<p>上面的这个例子存在这二义性，很遗憾JavaCC不支持这样的回溯，因此我们得用其他的方法来解决。</p>

<p>我们可以用以下的规则来替换:</p>

<pre><code class="language-java">void Input() :
{}
{
&quot;a&quot; &quot;b&quot; &quot;c&quot; [ &quot;c&quot; ]
}
</code></pre>

<p>或者</p>

<pre><code class="language-sql">void Input() :
  {}
  {
    &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;c&quot;
  |
    &quot;a&quot; &quot;b&quot; &quot;c&quot;
  }
</code></pre>

<p>我们建议使用第一种规则，因为它只需要遍历一遍就可以了，而第二种提供的第一种选择<code>abcc</code>不符合<code>abc</code>，所以它提供的第二种选择仍然需要再遍历一遍。</p>

<p>所以我们写语法规则很重要，不但影响结果，也影响性能。</p>

<p>而所谓的Lookahead，就是往前能看的字符数，默认是1. 比如上面的lookahead 就是只能看到下一个字符。</p>

<h3 id="toc_10">3.2 语法解析器的选择顺序</h3>

<p>语法解析采用自定向下的顺序进行选择，比如以下这个语法规则：</p>

<pre><code class="language-java">  void basic_expr() :
  {}
  {
    &lt;ID&gt; &quot;(&quot; expr() &quot;)&quot; // Choice 1
  |
    &quot;(&quot; expr() &quot;)&quot;  // Choice 2
  |
    &quot;new&quot; &lt;ID&gt;    // Choice 3
  }
</code></pre>

<p>它的选择顺序可以用伪代码表示, 由此可见它是按照代码的顺序来选择的。</p>

<pre><code class="language-java">if (next token is &lt;ID&gt;) {
    choose Choice 1
  } else if (next token is &quot;(&quot;) {
    choose Choice 2
  } else if (next token is &quot;new&quot;) {
    choose Choice 3
  } else {
    produce an error message
  }
</code></pre>

<p><strong><em>Example1</em></strong></p>

<p>在lookhead为1的情况下，JavaCC如果选择了前一个分支就不会进入下一个分支了，比如以下如果首先输入<ID> Token就会进入第一个分支，不会再进入第一个分支及时接下来的是字符是&quot;.&quot;。而因为第一个分支没有匹配上所以会报解析错误。</p>

<pre><code class="language-java">  void basic_expr() :
  {}
  {
    &lt;ID&gt; &quot;(&quot; expr() &quot;)&quot; // Choice 1
  |
    &quot;(&quot; expr() &quot;)&quot;  // Choice 2
  |
    &quot;new&quot; &lt;ID&gt;    // Choice 3
  |
    &lt;ID&gt; &quot;.&quot; &lt;ID&gt;   // Choice 4
  }
</code></pre>

<p>不过幸好JAVA会提醒你有错误，我们需要充分解决这些冲突，它也给你提供了意见Lookahead设置为2.</p>

<pre><code class="language-java">Warning: Choice conflict involving two expansions at
         line 25, column 3 and line 31, column 3 respectively.
         A common prefix is: &lt;ID&gt;
         Consider using a lookahead of 2 for earlier expansion.

</code></pre>

<p><strong><em>Example2</em></strong></p>

<p>我们再来看一个冲突的例子，</p>

<pre><code class="language-java">  void identifier_list() :
  {}
  {
    &lt;ID&gt; ( &quot;,&quot; &lt;ID&gt; )*
  }
</code></pre>

<p>它的选择逻辑伪代码如下：</p>

<pre><code class="language-java">while (next token is &quot;,&quot;) {
    choose the nested expansion (i.e., go into the (...)* construct)
    consume the &quot;,&quot; token
    if (next token is &lt;ID&gt;) consume it, otherwise report error
  }
</code></pre>

<p>如果我在其他语法规则上调用identifier_list这个规则，</p>

<pre><code class="language-java">void funny_list() :
{}
{
identifier_list() &quot;,&quot; &lt;INT&gt;
}
</code></pre>

<p>那么又会有以下的警告,因为语法解析器不知道，&#39;,&#39;应该属于内层identifier_list的还是最外层的，它决定了后面的字符是否能命中<code>&lt;INT&gt;</code>。</p>

<pre><code class="language-java">Warning: Choice conflict in (...)* construct at line 25, column 8.
         Expansion nested within construct and expansion following construct
         have common prefixes, one of which is: &quot;,&quot;
         Consider using a lookahead of 2 or more for nested expansion.

</code></pre>

<p>而解决这个问题需要我们重写解析规则,主要原则，能尽量使用不同的TOKEN。</p>

<pre><code class="language-java">  void funny_list() :
  {}
  {
    &lt;ID&gt; &quot;,&quot; ( &lt;ID&gt; &quot;,&quot; )* &lt;INT&gt;
  }

</code></pre>

<h3 id="toc_11">3.3 怎么使用lookahed</h3>

<p>当有时候，语法规则太复杂，无法进行重写后优化，那我们可以来修改lookahead。</p>

<p>我们可以设置全局的lookahead 在Option部分。也可以设置局部的部分。因为增加lookahead值后面比较的字符长度，因此值越大性能越差，我们建议使用局部的。</p>

<p>我们用设置lookahead的方法来解决之前例子碰到的问题</p>

<p><strong><em>Example1</em></strong></p>

<pre><code class="language-java">  void basic_expr() :
  {}
  {
    LOOKAHEAD(2)
    &lt;ID&gt; &quot;(&quot; expr() &quot;)&quot; // Choice 1
  |
    &quot;(&quot; expr() &quot;)&quot;  // Choice 2
  |
    &quot;new&quot; &lt;ID&gt;    // Choice 3
  |
    &lt;ID&gt; &quot;.&quot; &lt;ID&gt;   // Choice 4
  }

</code></pre>

<p>它的解析选择逻辑的伪代码:</p>

<pre><code class="language-java"> if (next 2 tokens are &lt;ID&gt; and &quot;(&quot; ) {
    choose Choice 1
  } else if (next token is &quot;(&quot;) {
    choose Choice 2
  } else if (next token is &quot;new&quot;) {
    choose Choice 3
  } else if (next token is &lt;ID&gt;) {
    choose Choice 4
  } else {
    produce an error message
  }
</code></pre>

<p>当我们优选读取两个字符并进行比较时候，当我们输入<code>&lt;ID&gt;.&lt;ID&gt;</code>时候就会进入第4分支。</p>

<p>同样 <strong><em>Example2</em></strong><br/>
<code>java<br/>
  void identifier_list() :<br/>
  {}<br/>
  {<br/>
    &lt;ID&gt; ( LOOKAHEAD(2) &quot;,&quot; &lt;ID&gt; )*<br/>
  }<br/>
</code></p>

<pre><code class="language-java"> while (next 2 tokens are &quot;,&quot; and &lt;ID&gt;) {
    choose the nested expansion (i.e., go into the (...)* construct)
    consume the &quot;,&quot; token
    consume the &lt;ID&gt; token
  }
</code></pre>

<h5 id="toc_12">Lookahead的一般模式</h5>

<pre><code class="language-java"> LOOKAHEAD( amount,
             expansion,
             { boolean_expression }
           )
</code></pre>

<p>amount指定了Lookahead的token个数， expansion 指定了lookahead的句法条件，boolean_expression指定了lookahead的语法条件。</p>

<p>如果expansion指定了，那么amount的默认值是2147483647。也就是说lookahead无限大，直到找到了符合expansion句法条件的token为止。</p>

<p>否则的话amount默认为0(boolean_expression必须被指定，boolean_expression为true)。</p>

<p>我们来看以下几个例子</p>

<p><strong><em>Example3</em></strong></p>

<pre><code class="language-java">
## 一直找到ClassDeclaration的Token条件，否则就lookahead长度2147483647。
  void TypeDeclaration() :
  {}
  {
    LOOKAHEAD(ClassDeclaration()) 
    ClassDeclaration()
  |
    InterfaceDeclaration()
  }
  
  ## 解析伪代码
    if (the tokens from the input stream match ClassDeclaration) {
    choose ClassDeclaration()
  } else if (next token matches InterfaceDeclaration) {
    choose InterfaceDeclaration()
  } else {
    produce an error message
  }

</code></pre>

<p><strong><em>Example4</em></strong></p>

<pre><code class="language-java">
  void TypeDeclaration() :
  {}
  {
    # 在10个字符以及匹配到class中满足一个就性
    LOOKAHEAD(10, ( &quot;abstract&quot; | &quot;final&quot; | &quot;public&quot; )* &quot;class&quot; )
    ClassDeclaration()
  |
    InterfaceDeclaration()
  }
  
  # 语法解析伪代码
  
    if (the nest set of tokens from the input stream are a sequence of
      &quot;abstract&quot;s, &quot;final&quot;s, and &quot;public&quot;s followed by a &quot;class&quot; and LOOKAHEAD determination is not permitted to go beyond 10 tokens.) {
    choose ClassDeclaration()
  } else if (next token matches InterfaceDeclaration) {
    choose InterfaceDeclaration()
  } else {
    produce an error message
  }
</code></pre>

<p><strong><em>Example5</em></strong></p>

<pre><code class="language-java">  void BC() :
  {}
  {
    &quot;b&quot;
    [ LOOKAHEAD( { getToken(1).kind == C &amp;&amp; getToken(2).kind != C } )
      &lt;C:&quot;c&quot;&gt;
    ]
  }
  
  # 语法解析逻辑伪代码
    if (next token is &quot;c&quot; and following token is not &quot;c&quot;) {
    choose the nested expansion (i.e., go into the [...] construct)
  } else {
    go beyond the [...] construct without entering it.
  }
</code></pre>

<p>*** 总体来说lookahead的功能还是很强大且灵活的，我们合理使用lookahead以及优化解析逻辑相结合往往能解决碰到的冲突 ***</p>

<h2 id="toc_13">4.总结</h2>

<p>本文基于一些参考资料，以及总结我使用JavaCC的心得，对JavaCC如何使用以及如何解决冲突进行描述。</p>

<h2 id="toc_14">5. 参考文献</h2>

<ul>
<li><a href="https://javacc.org/tutorials/lookahead">JavaCC官方文档</a></li>
<li><a href="http://zhoujinhuang.iteye.com/blog/169252">JAVACC 入门</a></li>
<li><a href="https://github.com/apache/calcite">Apache Calcite</a></li>
<li><a href="http://blog.csdn.net/bhq2010/article/details/8763920">JavaCC使用小结</a></li>
</ul>

<hr/>

<h4 id="toc_15">本文完。</h4>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-state">http://lamborryan.github.io/gobblin-state</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Data Vault 模型初探]]></title>
    <link href="www.lamborryan.com/14878594058587.html"/>
    <updated>2017-02-23T22:16:45+08:00</updated>
    <id>www.lamborryan.com/14878594058587.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">Data Vault的定义</a>
</li>
<li>
<a href="#toc_1">Data Vault的组件</a>
<ul>
<li>
<a href="#toc_2">Hub</a>
</li>
<li>
<a href="#toc_3">Link</a>
</li>
<li>
<a href="#toc_4">Satellite</a>
</li>
<li>
<a href="#toc_5">Point In Time 辅助表</a>
</li>
</ul>
</li>
<li>
<a href="#toc_6">Data Vault的参考原则</a>
<ul>
<li>
<a href="#toc_7">关于Hub的原则</a>
</li>
<li>
<a href="#toc_8">关于Link的原则</a>
</li>
<li>
<a href="#toc_9">关于Satellite的原则</a>
</li>
</ul>
</li>
<li>
<a href="#toc_10">一些优化</a>
</li>
<li>
<a href="#toc_11">Data Vault 2.0</a>
</li>
<li>
<a href="#toc_12">数据集市</a>
</li>
<li>
<a href="#toc_13">总结</a>
</li>
<li>
<a href="#toc_14">参考文献</a>
<ul>
<li>
<ul>
<li>
<a href="#toc_15">本文完</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>Data Vault被视为新一代的数据仓库技术，还是得到广泛的关注的。它综合了ER模型和Star Schema模型的一些优点，也克服了一些缺点。最近花了点时间学习了Data Vault模型，所以有了这篇文章。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">Data Vault的定义</h2>

<p>Data Vault是一个面向细节，追踪历史的，由一些规范化数据表组成的唯一的关联表集，用来支持一个或者多个业务功能域。</p>

<p>Data Vault模型用来架构一个企业级数据仓库(EDW),而不是数据集市。在某种程度上与Inmmon的原子数据仓库有点相似。</p>

<h2 id="toc_1">Data Vault的组件</h2>

<p>Data Vault 主要有Hub，Link，Satellite三个组成。它主要围绕业务功能域，以原子的业务实体逐步展开，进而扩充到整个数据仓库范围。其中Hub代表业务的实体主键，Link在Hub之间提供业务实体之间的业务关联与交易，而Satellite则提供Hub和Link的上下文描述信息。</p>

<h3 id="toc_2">Hub</h3>

<p>Hub是一个单个的数据表，是一个仅仅包含了简单的业务实体键值的列表，比如员工id，商品id等。如果这些实体键值丢失，那么该业务实体的上下文描述信息也会丢失。它主要包含以下的属性：</p>

<ul>
<li>代理键 (Surrogate Key)。一个跟业务无关的键值或者序列号。</li>
<li>业务主键 (Business Key)。 业务主键，唯一性。</li>
<li>数据装载时间 (Load Data)。记录该业务键被加载的时间。</li>
<li>记录源 (Record Source)。记录该业务键的来源，用来做数据源追踪之用。</li>
</ul>

<p><img src="media/14878594058587/14878618338988.jpg" alt=""/></p>

<p>上图为一个Customer Hub。ID 为代理键，CUSTOMER是主键, LOAD_DTS是数据装载时间，RCRD_SRC是记录源。</p>

<h3 id="toc_3">Link</h3>

<p>Link是一个多对多的3NF表，在两个或者多个业务实体之间，LINK表示业务实体HUB之间的业务关联或者交易。他主要包含以下的属性：</p>

<ul>
<li>代理键 (Surrogate Key)。一个跟业务无关的键值或者序列号。如果有多个Hub的主键加入，可以考虑使用代理键。</li>
<li>Hub1...Hubn 的主键。 多个与该Link相关的Hub的主键伸入到Link中来表示Hub之间的业务关系。</li>
<li>数据装载时间 (Load Data)。记录该业务键被加载的时间。</li>
<li>记录源 (Record Source)。记录该业务键的来源，用来做数据源追踪之用。</li>
</ul>

<p><img src="media/14878594058587/14878622845384.jpg" alt=""/></p>

<p>上图中，中间表为Link表，上下两个Hub表(Hub_Customer和Hub_invoice)，Hub_Customer和Hub_invoice的ID分别对应Link表的CSID和INVOICE ID</p>

<h3 id="toc_4">Satellite</h3>

<p>Satellite是关于Hub或者Link的上下文描述信息。这些信息有可能随着时间发生变化。因此，Satellite不仅能存储新的数据，而且还要包含变化前的数据。它主要包含:</p>

<ul>
<li>Satellite主键。Hub或者Link的主键伸入到Satellite作为主键。</li>
<li>Satellite主键。数据装载时间(Load Date) 描述该信息在数据仓库的装载时间，也就是什么时候起有效。为了保存历史数据，该属性也作为了主键的一部分。有时候会与End Date(时效时间)一起用。</li>
<li>数据装载时间 (Load Data)。记录该业务键被加载的时间。</li>
<li>记录源 (Record Source)。记录该业务键的来源，用来做数据源追踪之用。</li>
</ul>

<p><img src="media/14878594058587/14878633631576.jpg" alt=""/></p>

<p>Satellite类似与Star Schema模型的第二类缓慢变化维，保证了粒度级别的增量数据，用来为相应的Hub或者Link提供上下文描述信息。</p>

<p>上图中可以看出，上表是Hub_CUSTOMER, 下表是Satellite_Customer,CS_ID和LOAD_DTS成为Satellite_Customer的主键。CS_ID为1的多个行对应了Hub_CUSTOMER的一个CUSTOMER ID.</p>

<h3 id="toc_5">Point In Time 辅助表</h3>

<p>如果一个Hub有多个Satellite，通常需要一个Point In Time辅助表来协助同步多个Satellite的不同时间版本上下文信息。</p>

<p><img src="media/14878594058587/14878637972708.jpg" alt=""/></p>

<p>上图中，Customer Name Satellite和Customer Address Satellite的数据缓慢变化是没有同步对应的，比如Name Satellite的哪条CSID=1 和 Address Satellite的哪条CSID=1是同一时刻的数据。这时就建立了最上面的这张PID表，新建NAME_LOAD_DTS和ADDRESS_LOAD_DTS字段来对Name Satellite和Address Satellite进行对应，实现时间同步。如此之后，Name Satellite和Address Satellite就变得有序了。</p>

<h2 id="toc_6">Data Vault的参考原则</h2>

<h3 id="toc_7">关于Hub的原则</h3>

<ul>
<li>Hue的主键不能够直接深入到其他Hub里面。也就是说，不存在父子关系的Hub。各个Hub之间的关系是平等的。这就是Data Vault能保持灵活性和扩展性的关键。</li>
<li>Hub之间必须通过Link相关联，通过Link可以连接多个Hub。</li>
<li>必须至少有两个Hub才能产生一个有意义的Link。</li>
<li>Hub的键总是伸出去的(到Link或者Satellite)。</li>
</ul>

<h3 id="toc_8">关于Link的原则</h3>

<ul>
<li>Link可以跟其他Link相关联</li>
<li>Hub和Link都可以使用代理键，Satellite不适用代理键。</li>
<li>业务主键从来不会改变，就是说Hub的主键不会改变。</li>
<li>Link可能包含代理键。</li>
</ul>

<h3 id="toc_9">关于Satellite的原则</h3>

<ul>
<li>Satellite必须是连接到Link或者Hub上才有确定的含义。</li>
<li>Satellite必须包含装载时间Load_DTS, 从而包含历史数据，并且没有重复的数据。</li>
<li>由于数据信息的类型或者变化频率快慢的差别，描述信息数据可能会被分割开到多个Satellite之中去。</li>
</ul>

<h2 id="toc_10">一些优化</h2>

<p>在《Data Vault Series》系列中，提到了Business Data Vault (数据)，他在Data Vault  的基础上 增加了一些优化来快速解决join的问题，比如 <a href="http://www.vertabelo.com/blog/technical-articles/data-vault-series-the-business-data-vault">Bridge Tables</a>.</p>

<p>如果是Data Vault 设计就是一下这个图，<br/>
<img src="media/14878594058587/14883776431803.jpg" alt=""/></p>

<p>建立Bridge Table之后就是</p>

<p><img src="media/14878594058587/14883776751896.jpg" alt=""/></p>

<p>有了Bridge Table之后，我们可以少join需要表。详细内容见文章<a href="http://www.vertabelo.com/blog/technical-articles/data-vault-series-building-an-information-mart-with-your-data-vault">《Data Vault Series (4)》</a></p>

<h2 id="toc_11">Data Vault 2.0</h2>

<p>相比于Data Vault 1.0， Data Vault 2.0 给出了完整的数仓建设结构，他使用了实时和离线结合，使用了NOSQL数据库。不过，体系结构超出了本文范围。本文主要介绍Data Vault 2.0建模方法论上的新加功能。</p>

<p>Data Vault 2.0 模型最大的变化就是将Hub Link的主键由Integer型变化为Hash Key，一般是经过MD5处理。作者认为经过Hash key处理后，主键的长度固定，因此在进行Hub Link Satellite进行关联时候能起到性能优化。但是<strong><em>我并不认同这个观念</em></strong>。</p>

<h2 id="toc_12">数据集市</h2>

<p>一般使用Data Vault构建企业的原子数据仓库，之后在上面用星型模型构建企业数据集市，这里就涉及到将Data Vault转星型模型，我们可以看这篇文章<a href="http://www.vertabelo.com/blog/technical-articles/data-vault-series-building-an-information-mart-with-your-data-vault">《Data Vault Series (4)》</a></p>

<h2 id="toc_13">总结</h2>

<p>Data Vault 是个很灵活的敏捷建模方法。它解决部分ER模型和星型模型的缺点。但是同样引进了新的问题，大量的Hub Link Satellite的存在，使得join操作特别多，当数据量巨大时候，join操作往往是最费时间的。因此，对于Data Vault模型应用于大数据领域的效果，我们有待考察。</p>

<p>本文简要介绍了Data Vault的模型，更多的例子和深入的内容请看参考文献的《Data Vault Series》系列文章。</p>

<h2 id="toc_14">参考文献</h2>

<ul>
<li><a href="http://www.doc88.com/p-97036345456.html">下一代数据仓库模型Data Vault的研究及其应用</a></li>
<li><a href="http://www.vertabelo.com/blog/technical-articles/data-vault-series-data-vault-2-0-modeling-basics">Data Vault Series (2) Data Vault 2.0 Modeling Basics</a></li>
<li><a href="http://www.vertabelo.com/blog/technical-articles/data-vault-series-agile-modeling-not-an-option-anymore">Data Vault Series (1) Agile Modeling: Not an Option Anymore</a></li>
<li><a href="http://www.vertabelo.com/blog/technical-articles/data-vault-series-the-business-data-vault">Data Vault Series (3) The Business Data Vault</a></li>
<li><a href="http://www.vertabelo.com/blog/technical-articles/data-vault-series-building-an-information-mart-with-your-data-vault">Data Vault Series (4) Building an Information Mart With Your Data Vault</a></li>
</ul>

<hr/>

<h4 id="toc_15">本文完</h4>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-state">http://lamborryan.github.io/gobblin-state</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入学习维度表]]></title>
    <link href="www.lamborryan.com/14876860100279.html"/>
    <updated>2017-02-21T22:06:50+08:00</updated>
    <id>www.lamborryan.com/14876860100279.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">1. 组合维度</a>
<ul>
<li>
<a href="#toc_1">1.1 关联维度属性的两种方法</a>
<ul>
<li>
<a href="#toc_2">描述环境的明确关系</a>
</li>
<li>
<a href="#toc_3">描述亲和性的隐含关系</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">1.2 如何进行维度组合</a>
</li>
</ul>
</li>
<li>
<a href="#toc_5">2. 拆分维度</a>
<ul>
<li>
<a href="#toc_6">2.1 傻瓜式的拆分</a>
</li>
<li>
<a href="#toc_7">2.2 使用微型维度来进行拆分</a>
</li>
</ul>
</li>
<li>
<a href="#toc_8">3. 角色维度</a>
</li>
<li>
<a href="#toc_9">4. 空值处理</a>
<ul>
<li>
<a href="#toc_10">维度列</a>
</li>
<li>
<a href="#toc_11">事实表的空外键</a>
</li>
<li>
<a href="#toc_12">空值时的特殊处理</a>
</li>
</ul>
</li>
<li>
<a href="#toc_13">5. 行为维度</a>
<ul>
<li>
<a href="#toc_14">与另一个维度表关联</a>
</li>
<li>
<a href="#toc_15">历史事实</a>
</li>
<li>
<a href="#toc_16">分类事实</a>
</li>
<li>
<a href="#toc_17">行为维度设计要素</a>
</li>
</ul>
</li>
<li>
<a href="#toc_18">6. 总结</a>
</li>
</ul>


<p>维度表是实现强有力分析的基础，本文主要介绍一些维度设计的高级主题。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">1. 组合维度</h2>

<p>实际应用中，我们有时候很难确定如何将维度属性放到同一个维度表中。比如顾客和销售是否是一个维度，商品和品牌是否是一个维度。通过本小节你就能知道如何去组合维度。</p>

<h3 id="toc_1">1.1 关联维度属性的两种方法</h3>

<p>维度模型中维度属性的之间的关系，不像ER模型那么明确。所以我们需要额外的自己去发掘维度属性间的关系。</p>

<h4 id="toc_2">描述环境的明确关系</h4>

<p>每一个事实表中都有一个或者多个引用维度表的外键。这些引用为事实表提供了维度环境。而这些链接也看成了维度表之间存在关系的信息，这是明确的关系。</p>

<p><img src="media/14876860100279/14876867899584.jpg" alt=""/></p>

<p>图中，Product，SalesPerson，Day， Customer，Order_info这些维度通过事实表建立了明确的联系，这些联系我们一眼就可以确定。这些关系都是基于事实表，也就是过程建立的。</p>

<h4 id="toc_3">描述亲和性的隐含关系</h4>

<p>与ER模型不同，维度模型通过冗余了数据，使得原先一些明确的关系变得隐秘了。比如在Product维度表中，product和brand他们在一张共享表内，他们的关系就变成隐含关系了。</p>

<p>当然我们也可以把Brand维度拆出来，和Product通过代理建连接，他们的关系也变成了明确关系，但是这样就变成了雪花模型，大大加大了分析复杂度，这里我们并不提倡。</p>

<p>product与brand的关系是一对多的关系，即product是brand的成员。相比于product与customer这种通过业务过程建立的明确关系，这是一种不依赖于业务活动的自然的亲和性。</p>

<h3 id="toc_4">1.2 如何进行维度组合</h3>

<p>基于1.1节我们就可以给出维度组合的方法了。</p>

<ul>
<li>如果两个维度属性共享一个自然的亲和性关系，并且同时出现在一个环境时，那么他们就可以组成一个维度表。如果没有订单，product也会有brand属性，他们的关系是不依赖于业务过程或者事实的。这些维度属性往往只能在一种方法或者一种环境中使用。比如除了product，brand还可以跟其他什么维度结合？</li>
<li>如果两个维度属性的关系由事物或者活动来决定，并且存在于不同的环境之中，应该将他们放置在不同的维度表中。他们的关系是依赖于事实表的，当销售和客户之间有事实发生，他们之间就有了关系。当这个事实没有发生，他们之间就没有关系。</li>
</ul>

<h2 id="toc_5">2. 拆分维度</h2>

<p>当一个维度表的宽度特别大时，且有很多维度发生缓慢变化时候，我们的开发维护就会变得特别困难。试想一下，当很多维度发生缓慢变化，那么对于整个维度表的来讲变化就会很剧烈。这个时候我们需要拆分维度表。</p>

<h3 id="toc_6">2.1 傻瓜式的拆分</h3>

<p>之所以取傻瓜式的拆分这个名字，主要还是从反面来讲解这个方法，当然也是不推荐的。</p>

<p><img src="media/14876860100279/14876882495513.jpg" alt=""/></p>

<p>上图可以看出，他将Customer维度表拆分成了Customer_part1和Customer_part2。两者共享相同customer_key且一一对应。</p>

<p>这样的拆分有以下几大问题:</p>

<ul>
<li>主键连接，大大增加分析复杂度</li>
<li>主键一一对应，加大了ETL开发难度</li>
<li>当part2的某个属性缓慢变化时，part1的相应属性也需要做缓慢变化处理。同理part1的属性缓慢变化。反而加大的etl的开发难度。</li>
</ul>

<p>所以这种方式的拆分，没有更本上解决问题。</p>

<h3 id="toc_7">2.2 使用微型维度来进行拆分</h3>

<p>我们可以将稳定的核心的维度属性保留，将那些不稳定，缓慢变化的维度属性独立构成一个或者多个微型维度。比如以下这个例子</p>

<p>原始的POLICY维度表中，policy_holder和address等核心维度没有发生变化，但是family_size和marital_status等维度发生了缓慢变化。<br/>
<img src="media/14876860100279/14876887963530.jpg" alt=""/></p>

<p>现在将上表用微型维度来进行拆分，微型维度有自己的代理键，并可以关联到事实表中。</p>

<p><img src="media/14876860100279/14876888999557.jpg" alt=""/></p>

<p>通过将原来的POLICY维度拆分成现有的POLICY维度和POLICY_COVERAGE两个维度。POLICY只保留稳定的，不变的，核心维度属性，比如policy_holder和address。 POLICY_COVERAGE这个微型维度包含了family_size和marital_status等缓慢变化，且可以枚举所有可能的微型维度属性。</p>

<p>通过这样，数据的增加大大的得到了控制。</p>

<p>当然利用微型维度进行拆分也是有缺点的，拆分前我可以浏览整个维度的属性非常简单，拆分后就需要进行两表的关联。当然我们也可以在POLICY表中增加POLICY_COVERAGE的代理键，这样就可以对最新状态的微型维度的维度属性进行浏览。注意哦，这里只能浏览最新状态，历史状态是无法浏览的。</p>

<p><img src="media/14876860100279/14876892825490.jpg" alt=""/></p>

<h2 id="toc_8">3. 角色维度</h2>

<p>业务过程中度量可以包含维度的多个实例，比如保险保单表中就有投保人，被投保人，他们可以都是用户表的一个实例。那么这两种关系被称为角色，在事实表中通过引用同一维度的多个外键表示。查询时则使用别名来进行区分。</p>

<p>维度表可以参与事实表的多个关系，每个关系称为一种角色。这种多对多的关系时候，没必要为维度建立多个副本，通过角色在事实表中连接维度的视图或别名到适当的外键上。</p>

<h2 id="toc_9">4. 空值处理</h2>

<p>在关系型数据库中会允许空值的存在，但是如果在数据仓库中存在空值将对分析结果产生不确定性，因此我们需要对空值进行处理。</p>

<h3 id="toc_10">维度列</h3>

<p>如果在维度列中存在空值，那么当我们进行查询时候, 比如</p>

<pre><code class="language-sql">select
count(1) as cnt
from a
where tax_exampt_status &lt;&gt; &quot;Tax Exempt&quot;
</code></pre>

<p>就会把空值的结果遗漏。正确的写法是：</p>

<pre><code class="language-sql">select
count(1) as cnt
from a
where tax_exampt_status &lt;&gt; &quot;Tax Exempt&quot;
    or tax_exampt_status is null
</code></pre>

<p>这种处理如果都在分析的时候进行，不但繁琐还容易出错，所以我们要将空值处理掉。</p>

<p><strong><em>在维度中不允许存储空值，而要选择某个值作为当数据无效时存储的值，比如N/A</em></strong></p>

<h3 id="toc_11">事实表的空外键</h3>

<p>有时候事实表不能关联上维度表，因为事实表的外键为空。一般情况，只能使用外连接来关联维度表以克服这个问题。我们不能直接把空外键的事实行过滤掉，因为这样影响事实的分析。所以我们还是得补上外键的值，使得外键列不为空。</p>

<h3 id="toc_12">空值时的特殊处理</h3>

<ul>
<li>如果是STRING类型建议用类似“N/A”的来替换，如果是整数就用0，如果是时间就用未来的时间，比如“9999-12-31”</li>
<li>如果某一刻时间，维度表中的记录还未生成，事实表中的记录已经生成。或者事实表的某记录键出现错误。这个时候都可以在维度表中新建一条记录分别type为“Invalid”，“Unkonow”，其他为&quot;N/A&quot;，如下图所示</li>
</ul>

<p><img src="media/14876860100279/14877769003698.jpg" alt=""/></p>

<ul>
<li>如果一条事实表中，有两个时间时段，start_date,end_date。 在end_date还未更新，start_date已经更新，那么我们可以将本来为null的end_date 设为未来时间比如&quot;9999-12-31&quot;</li>
</ul>

<p><img src="media/14876860100279/14877770289339.jpg" alt=""/></p>

<h2 id="toc_13">5. 行为维度</h2>

<p>何为行为维度，就是有时候需要将事实表的一些事实转换为维度。它将一些表报时候的查询环境固化到维度表中。比如&quot;产生超过100万美元的订单的用户与产生50万美元或更少订单的客户比较，有更多折扣吗&quot;，该分析需求如果直接分析比较复杂，会有很多子查询。但是当我们把“订单的金额”这个指标，固化到用户表的维度属性中，那查询就非常简单了。</p>

<h3 id="toc_14">与另一个维度表关联</h3>

<p><img src="media/14876860100279/14877773319911.jpg" alt=""/></p>

<p>我们来看这个例子，我们从ORDER_FACTS这个事实表中计算出了first_order_date,last_order_date,annual_sales,annual_sales_group这几个指标，并关联到CUSTOMER维度表中，作为了它的行为属性。</p>

<h3 id="toc_15">历史事实</h3>

<p>行为属性也能捕获维度中关于有效存放时间的具有历史意义的事实，上图中annual_sales累计计算了过去一年的历史事实。</p>

<p>有了这个行为属性，我们查看过去一年下单金额超过100万的用户只需要 <code>where annual_sales &gt; 1000000</code> 而不需要进行子查询了。</p>

<h3 id="toc_16">分类事实</h3>

<p>annual_sales_group就是个分类事实作为行为维度的例子。</p>

<ul>
<li>年销售额低于500000</li>
<li>年销售额在500000与1000000之间</li>
<li>年销售额超过1000000</li>
</ul>

<p>同样大大简化了查询。</p>

<h3 id="toc_17">行为维度设计要素</h3>

<p>行为维度大大简化了分析查询，但是由于行为维度是基于事实表得出的，他本身就是缓慢变化的，因此一旦使用它增加维护成本，我们需要权衡。如果这种需求较大，可以考虑作为行为维度。如果较少，还是放在临时查询事实表为好。</p>

<h2 id="toc_18">6. 总结</h2>

<p>本文主要介绍了维度表设计的一些高级主题，在后续的文章中，我们仍然接着展开维度表的设计。</p>

<p>本文完。</p>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-state">http://lamborryan.github.io/gobblin-state</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[维度一致性问题]]></title>
    <link href="www.lamborryan.com/14875994254012.html"/>
    <updated>2017-02-20T22:03:45+08:00</updated>
    <id>www.lamborryan.com/14875994254012.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">1. 维度与横向钻取</a>
<ul>
<li>
<a href="#toc_1">1.1 造成横向钻取失败的原因</a>
</li>
</ul>
</li>
<li>
<a href="#toc_2">2. 一致性维度</a>
<ul>
<li>
<a href="#toc_3">2.1 共享维度表</a>
</li>
<li>
<a href="#toc_4">2.2 一致性上卷维度</a>
</li>
<li>
<a href="#toc_5">2.3 一致的退化维度</a>
</li>
<li>
<a href="#toc_6">2.4 重叠维度</a>
</li>
</ul>
</li>
<li>
<a href="#toc_7">3. 使用矩阵图表来规划一致性维度</a>
</li>
<li>
<a href="#toc_8">4. 总结</a>
<ul>
<li>
<a href="#toc_9">本文完</a>
</li>
</ul>
</li>
</ul>


<p>维度表是整个数据仓库的骨架，好的维度表设计能确保整个数据仓库的高可用性，反之不好的维度表设计使得数据仓库可用性大大降低。如果维度表不能实现一致性，那么多个星型模型不能实现横向钻取，从而形成信息孤岛。</p>

<p>本文主要介绍维度表的一致性要求以及问题。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">1. 维度与横向钻取</h2>

<p>前面提到，多个事实表进行连接是通过横向钻取实现的，而实现横向钻取的前提是维度的一致性。维度是确保将不同过程中的信息集成起来的实现横向钻取活动的关键。当维度的结构或内容不同时，横向钻取就会失败，不同的过程将不能协同。支持横向钻取时，多维表并不需要完全相同。当一个维度表中的属性是另一个维度表属性的子集时，横向钻取也是可以实现的。</p>

<h3 id="toc_1">1.1 造成横向钻取失败的原因</h3>

<p>我们通过以下这个例子来分析横向钻取失败的原因。</p>

<p><img src="media/14875994254012/14876000556258.jpg" alt=""/></p>

<p>图中星型模型描述了订单和收益两个业务过程，可以发现两个星型模型都存在了以下几个维度，Day, SalesRep, Customer, Product。本来我们可以通过这些相同的维度来横向钻取两个业务过程并进行分析。但是实际情况并不如此，通过对比，不难发现在他们的产品维度上存在以下几个差异:</p>

<ul>
<li>维度结构的差异

<ul>
<li>收益星型模型的产品维度有type维度，订单星型模型没有。</li>
<li>表示同一事情的列在不同的星型模型中以不同的名字命名。比如收益星型模型的prod_cat和prod_name在订单星型中就叫做了prodict,category。 </li>
</ul></li>
<li>维度内容的差异

<ul>
<li>产品名称和分类的格式的差异。订单星型模型中的数据格式没有区分大小写且包含了标点符号，收益星型模型中的数据格式采用大写且不包含标点符号。当这些值进行join的时候会发现根本连接不起来。</li>
<li>名称不一致。订单模型中的产品“9*12 bubble mailer” 在收益模型中对应的为“STANDARD MAILER”</li>
<li>在订单星型模型中自然键的4444-22在收益模型中出现了两行。</li>
<li>订单星型模型中自然键6666-22收益模型中却没有。</li>
<li>SKU为5555-22的行在两个星型模型中分配了不同的代理键。</li>
</ul></li>
</ul>

<p>这些问题在进行多个事实表横向钻取时候都会对结果的准确性造成很大的影响。 </p>

<h2 id="toc_2">2. 一致性维度</h2>

<p>上文给出了不满足一致性维度的例子，那么什么样子是一致性维度呢。一致性维度的根本要求是，公共属性的结构和内容相同。下文给出了4种一致性维度。</p>

<h3 id="toc_3">2.1 共享维度表</h3>

<p>最常见的维度一致性形式发生在两个星型模型共享相同的逻辑维度时。这个共享可能是同一个物理表，也有可能有两个或者多个等价表组成。只要满足以下两个特性就是共享维度表:</p>

<ul>
<li>表共享相同的结构</li>
<li>表共享相同的内容</li>
</ul>

<h3 id="toc_4">2.2 一致性上卷维度</h3>

<p>保持一致性并不需要维度表完全相同。只要满足以下条件，不同的维度表也能支持横向钻取:</p>

<ul>
<li>表的维度属性是其他表的维度属性的子集</li>
<li>公共维度属性具有相同的结构和内容</li>
</ul>

<p>其中较小的那个叫一致性上卷，较大的那个称为基本维度。</p>

<p><img src="media/14875994254012/14876019122246.jpg" alt=""/></p>

<p>从上图中可以看出，MONTH表的维度属性是DAY表的子集，而这部分结构,比如month和year，具有相同的结构和内容。所以MONTH是一致性上卷，DAY是基础表。</p>

<h3 id="toc_5">2.3 一致的退化维度</h3>

<p>前文讲过，退化维度将维度属性存储在事实表中，往往用于标示事物或者标示文档。相同的退化维度可以在多个事实表中实现，因此可以在退化维度上执行横向钻取。它同样有根本要求：公共属性的结构和内容相同。</p>

<h3 id="toc_6">2.4 重叠维度</h3>

<p>当两个维度出现重叠属性时候，且重叠属性具有共享相同的结构和内容，那么重叠属性可以确保维度表的一致性。这种情况比较少见。</p>

<p><strong><em>重叠维度和是否需要生成第三章表的独立出重叠维度需要郑重考虑，因为第三章表的出现意味着采用了雪花模型，而一般情况下雪花模型是不提倡的，这在后面文章介绍。同时维护多个维度表的重叠维度也是比较麻烦的</em></strong></p>

<h2 id="toc_7">3. 使用矩阵图表来规划一致性维度</h2>

<p>一致性维度是维度建模的关键。在进行维度建模时候，有必要使用矩阵图表来规划维度的一致性，下图是利用矩阵图标规划维度一致性的例子。列代表了核心一致性维度，行代表了不同的过程和事实表，可通过在适当交叉点放置标志来阐明一致性。</p>

<p><img src="media/14875994254012/14876029234717.jpg" alt=""/></p>

<h2 id="toc_8">4. 总结</h2>

<p>在Inmon的数据仓库体系中，由于原子数据仓库是用ER模型建立的，所以它的维度一致性是弱化的。而独立的数据集市，只关心单一数据技术，更不需要企业级的一致性问题。只有Kimball的维度模型数据仓库维度的一致性。</p>

<p>本文完。</p>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-state">http://lamborryan.github.io/gobblin-state</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

<h3 id="toc_9">本文完</h3>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-state">http://lamborryan.github.io/gobblin-state</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[星型模型与多维数据集]]></title>
    <link href="www.lamborryan.com/14870800072371.html"/>
    <updated>2017-02-14T21:46:47+08:00</updated>
    <id>www.lamborryan.com/14870800072371.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">1.维度表特性</a>
<ul>
<li>
<a href="#toc_1">1.1 代理键和自然键</a>
</li>
<li>
<a href="#toc_2">1.2 丰富的维度集合</a>
<ul>
<li>
<a href="#toc_3">公共组合</a>
</li>
<li>
<a href="#toc_4">代码与描述符</a>
</li>
<li>
<a href="#toc_5">标志及标志值</a>
</li>
<li>
<a href="#toc_6">多列组合字段</a>
</li>
<li>
<a href="#toc_7">带有数字值的维度</a>
</li>
<li>
<a href="#toc_8">行为维度与混合属性</a>
</li>
<li>
<a href="#toc_9">基于相似性组合维度</a>
</li>
<li>
<a href="#toc_10">无相似性的杂项维度</a>
</li>
<li>
<a href="#toc_11">雪花模型和支架表</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_12">2. 事实表特性</a>
<ul>
<li>
<a href="#toc_13">具有不同时间的事实</a>
</li>
<li>
<a href="#toc_14">具有不同粒度的事实</a>
</li>
<li>
<a href="#toc_15">多业务过程事实表</a>
</li>
<li>
<a href="#toc_16">事实表的横向钻取</a>
</li>
</ul>
</li>
<li>
<a href="#toc_17">3. 缓慢变化维</a>
<ul>
<li>
<a href="#toc_18">3.1 变化类型1</a>
</li>
<li>
<a href="#toc_19">3.2 变化类型２</a>
</li>
<li>
<a href="#toc_20">3.3 如何选择变化类型</a>
</li>
<li>
<a href="#toc_21">本文完</a>
</li>
</ul>
</li>
</ul>


<span id="more"></span><!-- more -->

<h2 id="toc_0">1.维度表特性</h2>

<h3 id="toc_1">1.1 代理键和自然键</h3>

<ul>
<li>代理建(SK)是在数据仓库中产生的，他表示星型模型中维度表的唯一性，它不具备业务含义，一般用于处理缓慢变化维。</li>
<li>自然键(NK)是来源于源数据, 有可能一个实体中会有多个自然键，它具有业务含义。</li>
<li>使用代理键允许数据仓库对源系统发生的变化作出相应，这是因为数据仓库面向的是历史数据的查询，而历史数据的自然键是可以重复的，通过建立代理键来确保维度的唯一性。</li>
</ul>

<p><img src="media/14870800072371/14870807707669.jpg" alt=""/></p>

<p><strong><em>但是在实际应用中，我们并不会特意去使用代理键。第一点原因是，对于分布式计算系统，不存在事务的概念，对于每个表的记录生成全局唯一的稳定的代理键难度很大，此处稳定指某条记录每次生成的代理键都相同。第二点原因是，使用代理键会大大增加ETL的复杂性，对ETL任务的开发和维护成本很高</em></strong></p>

<h3 id="toc_2">1.2 丰富的维度集合</h3>

<p>维度为事实提供了环境，没有环境，事实也无法理解。那么如何建立维度呢，如何将源系统的属性转换为维度呢，以下面这个例子为例:</p>

<p><img src="media/14870800072371/14871677067873.jpg" alt=""/></p>

<h4 id="toc_3">公共组合</h4>

<p>操作系统中,　经常将数据元素尽可能的分解为构建其内容的多个组件。如例子中cust_name_first, cust_name_middle, cust_name_last三个属性就可以组合成人名。而在维度设计的时候，这些组件不但要包含在维度里面，还要尽可能的包含这些组件的组合，比如first_name, middle_initial, last_name, full_name, full_name_last_first。这样就很容易对他们进行分组，排序等操作，且进行一些优化。</p>

<h4 id="toc_4">代码与描述符</h4>

<p>操作系统中，往往一些属性会用代码的形式表示，比如type_code (002), 同时又有其他表来维护代码与描述的映射。比如city_code　0571的描述符是杭州。这大大使得分析查询复杂了。在维度设计中往往把代码和描述符都放在维度表中，使用者就可以根据自己的实际情况来进行过滤，访问和组织信息。比如例子中源数据表中是city_code，而在维度表中就变为了customer_type_code和customer_type_name了。</p>

<h4 id="toc_5">标志及标志值</h4>

<p>在操作系统中，往往使用布尔类型,　或者整数(0/1),　或者字符(Y/N, True/False)这些标志，这些方式便于存储。在维度设计时, 这些标志可用于过滤查询或分组事实, 但是不便于理解。通过采用描述符的值存储标志，可以更方便的使用标志。如例子中，源系统的credit_order_flag(N) 转换为维度表中的credit_order_flag(Not Credit Order)。</p>

<h4 id="toc_6">多列组合字段</h4>

<p>操作系统中通常包含由多个部分组合而成的字段列，各个部分包含不同的意义，比如账号代码，包含了公司标识符，账号代码，分类账号代码等。在维度设计的时候，全部的属性将被存储，用于分割该属性的多个子属性也将被存储。如果这些子属性是代码，那么还要增加相应的描述。比如region_code(01-701),　在维度表中不但包含了region_code(01-701),　还包含了country_code(01)和territory_code(701),　以及他们对应的描述符country_name(United States)以及territory_code(East)。</p>

<h4 id="toc_7">带有数字值的维度</h4>

<p>带有数值的属性很难区分到底是维度还是事实, 一般根据应用去分析。如果一个元素值用于过滤查询，排序数据，控制聚集，区分主从等，那他就是维度。如果对这个元素值进行相加等汇总操作就是事实。</p>

<h4 id="toc_8">行为维度与混合属性</h4>

<p>基于事实计算得到的维度称为行为维度，我们将在后续&lt;深入维度表&gt;中展开介绍。</p>

<h4 id="toc_9">基于相似性组合维度</h4>

<p>具有相似业务特征的维度放在相同的维度表中，比如跟品类有关的维度要么都放在产品维度表中，要么放在自己的维度表中。</p>

<h4 id="toc_10">无相似性的杂项维度</h4>

<p>我们会经常使用杂项维度来组合没有实际关系的维度。杂项维度表是多个杂项维度笛卡尔组合建立的,　所以没有代理键，事实表中的行只对应到部分的列和行上去。我们将在之后的文章中更深入的讲解。</p>

<h4 id="toc_11">雪花模型和支架表</h4>

<p>一般我们尽量少用雪花模型，我们会通过冗余把雪花模型转换到维度表中，或者退化维到事实表中。在之后的文章中会展开。</p>

<h2 id="toc_12">2. 事实表特性</h2>

<p>每个事实表通过获取<strong><em>业务过程</em></strong>的<strong><em>度量</em></strong>来表达业务过程的。一张事实表对应一个业务过程。何为业务过程，业务过程是某个业务的最小单位，比如交易这个业务，支付是个业务过程，退款是个业务过程。度量又叫事实，大多数是数字型的。事实表又可以包含一些维度，称为退化维。</p>

<p>在设计时候要求事实表的粒度是一致的。相对于维度的列宽行少，事实表则是行多列窄，且行增长速度快。对于事实表的事实可以分为可加性事实，半可加性事实，不可加性三种事实。</p>

<ul>
<li>可加性事实。比如交易金额就是可加性事实。</li>
<li>半可加性事实。半可加性是指只能按照特定纬度相加才有意义的度量值。比如账户余额，你能对今天的账户余额进行汇总，但是不能对历史的账户余额进行汇总。 </li>
<li>不可加性是指无论按照那个纬度都不可以相加，或者相加后没有任意的度量值。比如利润率这种类型的事实。</li>
</ul>

<p>在设计事实表的时候，我们要将不可加性事实转换为可加性事实，比如利润率是利润额度与订单额度的比值,　而利润额度与订单额度是可加的，所以在建事实表的时候需要把两者加到事实表中。</p>

<p>事实表所表达的细节层次被称为粒度，在星型模型中尽可能要求事实表的粒度是最细的，这样保证了分析的最大灵活性。</p>

<p>除了事物标识符外，多数情况下，适合选做退化维的维度最好放置在杂项维度中。比如订单id, 订单状态，订单时间等。</p>

<h3 id="toc_13">具有不同时间的事实</h3>

<p>如何区分多个业务过程，如果描述事件的两个或两个以上的事实不在同一时间发生，那么这些事实描述的是不同的过程。比如:</p>

<ul>
<li>根据日期，客户，产品分析订单数量</li>
<li>根据日期，客户，产品分析发货数量</li>
</ul>

<p>这种情况下，有两种方式来组织事实表。</p>

<p><img src="media/14870800072371/14873406216551.jpg" alt=""/><br/>
上图通过0来填补没有发货或者没有订单的情况。</p>

<p><img src="media/14870800072371/14873406967940.jpg" alt=""/><br/>
上图通过增加新的维度来判断当前记录是一次发货还是一个订单。</p>

<p>多个业务过程放入事实表，会妨碍对单个过程的分析。</p>

<h3 id="toc_14">具有不同粒度的事实</h3>

<p>另一种区分多个业务过程的方法是，当描述事件的两个或者多个事实具有不同的粒度时，它们描述的是不同的过程。比如:</p>

<ul>
<li>根据日期，客户，产品分析订单数量</li>
<li>根据日期，客户，产品和发货分析发货数量</li>
</ul>

<p><img src="media/14870800072371/14873403889888.jpg" alt=""/></p>

<p>有没有发货是通过shipper_key是否为0来区分的，要实现以上两个需求很麻烦。由此可见，这种多个业务过程的事实表造成了很大的理解和分析困难。所以建议一个业务过程对应一个事实表。</p>

<h3 id="toc_15">多业务过程事实表</h3>

<p>之前谈到，一般情况下一个业务过程对应一张事实表，也谈到了多个业务过程事实表的不利之处。但是实际使用中每个业务过程的数据量是不一致的，甚至差别巨大，又考虑到存储，性能以及特殊分析需求，有时会将多个业务过程合在一张事实表中。可以有两种方式进行设计，一行多列，以及一列多行。</p>

<p>表1:以订单为例(有两个业务过程refund和pay)，一行多列表示多业务过程事实表。</p>

<table>
<thead>
<tr>
<th>order_id</th>
<th>pay_time</th>
<th>pay_amt</th>
<th>refund_time</th>
<th>refund_amt</th>
</tr>
</thead>

<tbody>
<tr>
<td>1</td>
<td>2017-02-16 00:00:00</td>
<td>60</td>
<td>2017-02-17 00:00:00</td>
<td>50</td>
</tr>
</tbody>
</table>

<p>表2:一列多行</p>

<table>
<thead>
<tr>
<th style="text-align: center">order_id</th>
<th style="text-align: center">create_time</th>
<th style="text-align: center">amt</th>
<th style="text-align: center">type</th>
</tr>
</thead>

<tbody>
<tr>
<td style="text-align: center">1</td>
<td style="text-align: center">2017-02-16 00:00:00</td>
<td style="text-align: center">60</td>
<td style="text-align: center">pay</td>
</tr>
<tr>
<td style="text-align: center">1</td>
<td style="text-align: center">2017-02-17 00:00:00</td>
<td style="text-align: center">50</td>
<td style="text-align: center">refund</td>
</tr>
</tbody>
</table>

<p>所以还是非常灵活的。</p>

<p><strong><em>需要说明下，如果源数据在设计表的时候把业务过程区分多个业务过程的话，类似与表1，那么我们进行数据同步的时候能检测到并拆分多个业务过程，但是如果如表3这种设计用离线方式进行数据同步是很难拆分业务过程的。一般只能订阅binlog来实现</em></strong></p>

<p>表3: </p>

<table>
<thead>
<tr>
<th>order_id</th>
<th>create_time</th>
<th>modified_time</th>
<th>statue_code</th>
</tr>
</thead>

<tbody>
<tr>
<td>1</td>
<td>2017-02-16 00:00:00</td>
<td>2017-02-17 00:00:00</td>
<td>300</td>
</tr>
</tbody>
</table>

<p>表3中通过status_code来表示业务过程，比如300表示退款，他覆盖了之前的status_code(200支付)，以及支付时间modified_time,所以不能拆分业务过程。</p>

<p>所以尽量还是拆分业务过程，但是特殊情况下可以合并多个业务过程，还是要根据具体需求。关于事实表的设计，将在之后的文章中再详细讲解。</p>

<h3 id="toc_16">事实表的横向钻取</h3>

<p>两个事实表由于粒度的不一致，一般情况下不能直接把他们进连接，否则会有错误的结果，如果有连接需求可进行横向钻取。</p>

<p><img src="media/14870800072371/14873414451306.jpg" alt=""/></p>

<h2 id="toc_17">3. 缓慢变化维</h2>

<p>维度模型中，数据源的数据会发生变化从而使得维度也发生变化，这种变化相对于事实表的变化是缓慢的，所以称为缓慢变化维。</p>

<p><img src="media/14870800072371/14872561218701.jpg" alt=""/></p>

<p>在上图中，客户维度customer_id为9900011的记录变化了2次，分别是生日和地址，而在源数据中只能保存最新的一份，但是在我们数据仓库中会存放历史记录的。</p>

<p>如果我们的维度表不进行相应的处理，就会出现以前的事实对应现在的维度这种错乱的现象，这是不允许的。那么怎么来处理缓慢变化维呢，有以下两种方式。</p>

<h3 id="toc_18">3.1 变化类型1</h3>

<p>变化类型1, 重写维度，用最新的记录覆盖历史的记录。</p>

<p><img src="media/14870800072371/14872564258000.jpg" alt=""/></p>

<p>上图中进行修改之后，　订单事实表的1499对应到了新的维度表1499中,　生日也发生了变化。这就造成了前后指标的不一致性。</p>

<h3 id="toc_19">3.2 变化类型２</h3>

<p>变化类型2插入新的维度行，保留事实的历史环境。</p>

<p><img src="media/14870800072371/14872566507921.jpg" alt=""/></p>

<p>在上图可以看到，修改后，在维度表增加了customer_key为2507的新行，他跟customer_key为1499的有相同的customer_id，而在事实表中同样增加了一条customer_key为2507的记录，这样修改后的维度也有了新的事实。</p>

<p>但是对于给定的自然键customer_id, 有两条的记录存在，会对使用和理解造成麻烦。</p>

<h3 id="toc_20">3.3 如何选择变化类型</h3>

<p>星型模型的一个重要任务就是给维度表设计缓慢变化过程的规则。细心的同学会发现，上面的例子，第一次变化的是生日，第二次变化的是地址，上面的情景可以总结为:</p>

<ul>
<li>对维度表中任意给定的customer_id,如果数据源的date_of_birth发生改变，那么采用新值对已有存在的维度进行重写。变化类型2.</li>
<li>对维度表中任意给定的customer_id,如果数据源的state发生改变，那么在维度表中插入新行。变化类型2.</li>
</ul>

<p>为什么要这么处理，因为date_of_birth是固定的，只有当输入错误的时候我们才会去修改，所以它的历史数据是没有作用的，而state的历史记录是有意义的。</p>

<p><strong><em>为了维护维度表维护历史信息的能力, 多数情况下，我们都会用变化类型2来处理缓慢变化维。</em></strong></p>

<p>对于缓慢变化维的更多的处理技术，将在后面单独介绍。</p>

<h3 id="toc_21">本文完</h3>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-state">http://lamborryan.github.io/gobblin-state</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[企业级数据仓库体系结构]]></title>
    <link href="www.lamborryan.com/14869984530295.html"/>
    <updated>2017-02-13T23:07:33+08:00</updated>
    <id>www.lamborryan.com/14869984530295.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">企业级数据仓库体系结构分类</a>
</li>
<li>
<a href="#toc_1">Inmon的企业信息化工程</a>
</li>
<li>
<a href="#toc_2">Kimball的维度数据仓库</a>
</li>
<li>
<a href="#toc_3">独立型数据集市</a>
</li>
<li>
<a href="#toc_4">体系结构和维度设计</a>
<ul>
<li>
<a href="#toc_5">本文完</a>
</li>
</ul>
</li>
</ul>


<span id="more"></span><!-- more -->

<h2 id="toc_0">企业级数据仓库体系结构分类</h2>

<ul>
<li>Inmon的企业信息化工程</li>
<li>Kimball的维度数据仓库</li>
<li>独立型数据集市</li>
</ul>

<h2 id="toc_1">Inmon的企业信息化工程</h2>

<p>Inmon的体系结构中，先用ER模型(第3范式)建立一个企业级的原子数据仓库，该数据仓库是不对数据仓库应用软件提供服务的，因为原子数据的性质，该仓库尽可能的包括最底层的细节数据。随后，在原子数据仓库的基础上建立数据集市对外提供服务，也就是说数据集市和原子数据仓库是物理分开的。数据集市可以采用维度模型, 不一定非要用ER模型。</p>

<p><img src="media/14869984530295/14869985649523.jpg" alt=""/></p>

<h2 id="toc_2">Kimball的维度数据仓库</h2>

<p>相对于Inmon的原子数据仓库， Kimball提出了维度数据仓库。它是根据维度建模的原则来设计的，由一系列的星型模型或者多维数据集组成，并由他们尽可能详尽的细节数据。<br/>
虽然需要尽可能的避免，但是维度数据仓库可以被分析型系统直接访问。而数据集市是数据仓库中的主题区域，它可以使逻辑的，也可以是报表的子集。</p>

<p><img src="media/14869984530295/14870780143290.jpg" alt=""/></p>

<h2 id="toc_3">独立型数据集市</h2>

<p>独立型数据集市是一个分析型数据存储，并不在企业环境中被设计的，它只关注主题域。数据集市可能采用维度设计，ER关系模型或者其他的设计模型，它能快速，廉价的获得结果。虽然短期内能非常成功，但是当独立型集市支持多个主题时候，它将是灾难。它会导致信息孤岛。</p>

<p><img src="media/14869984530295/14870788989702.jpg" alt=""/></p>

<h2 id="toc_4">体系结构和维度设计</h2>

<p>对比以上三个体系结构:</p>

<p><img src="media/14869984530295/14870794697260.jpg" alt=""/></p>

<p>方法对比:<br/>
<img src="media/14869984530295/14870795494063.jpg" alt=""/><br/>
　</p>

<h3 id="toc_5">本文完</h3>

<ul>
<li>原创文章，转载请注明： 转载自<a href="http://lamborryan.github.io">Lamborryan</a>，作者：<a href="http://lamborryan.github.io/about/">Ruan Chengfeng</a></li>
<li>本文链接地址：<a href="http://lamborryan.github.io/gobblin-state">http://lamborryan.github.io/gobblin-state</a></li>
<li>本文基于<a href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。 如您有任何疑问或者授权方面的协商，请邮件联系我。<br/></li>
</ul>

]]></content>
  </entry>
  
</feed>
